{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370373</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Stankovic, Mr. Ivan</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349239</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rekic, Mr. Tido</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349249</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Doling, Mrs. John T (Ada Julia Bone)</td>\n",
       "      <td>female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>231919</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gronnestad, Mr. Daniel Danielsen</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8471</td>\n",
       "      <td>8.3625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Morley, Mr. Henry Samuel (\"Mr Henry Marshall\")</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250655</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>605</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Homer, Mr. Harry (\"Mr E Haven\")</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111426</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Moubarek, Master. Gerios</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2661</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>524</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hippach, Mrs. Louis Albert (Ida Sophia Fischer)</td>\n",
       "      <td>female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>111361</td>\n",
       "      <td>57.9792</td>\n",
       "      <td>B18</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "289          290         1       3   \n",
       "285          286         0       3   \n",
       "108          109         0       3   \n",
       "98            99         1       2   \n",
       "873          874         0       3   \n",
       "769          770         0       3   \n",
       "705          706         0       2   \n",
       "604          605         1       1   \n",
       "65            66         1       3   \n",
       "523          524         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "289                             Connolly, Miss. Kate  female  22.0      0   \n",
       "285                              Stankovic, Mr. Ivan    male  33.0      0   \n",
       "108                                  Rekic, Mr. Tido    male  38.0      0   \n",
       "98              Doling, Mrs. John T (Ada Julia Bone)  female  34.0      0   \n",
       "873                      Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
       "769                 Gronnestad, Mr. Daniel Danielsen    male  32.0      0   \n",
       "705   Morley, Mr. Henry Samuel (\"Mr Henry Marshall\")    male  39.0      0   \n",
       "604                  Homer, Mr. Harry (\"Mr E Haven\")    male  35.0      0   \n",
       "65                          Moubarek, Master. Gerios    male   NaN      1   \n",
       "523  Hippach, Mrs. Louis Albert (Ida Sophia Fischer)  female  44.0      0   \n",
       "\n",
       "     Parch  Ticket     Fare Cabin Embarked  \n",
       "289      0  370373   7.7500   NaN        Q  \n",
       "285      0  349239   8.6625   NaN        C  \n",
       "108      0  349249   7.8958   NaN        S  \n",
       "98       1  231919  23.0000   NaN        S  \n",
       "873      0  345765   9.0000   NaN        S  \n",
       "769      0    8471   8.3625   NaN        S  \n",
       "705      0  250655  26.0000   NaN        S  \n",
       "604      0  111426  26.5500   NaN        C  \n",
       "65       1    2661  15.2458   NaN        C  \n",
       "523      1  111361  57.9792   B18        C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age, Cabin and Embarked have missing data. Need to drop or impute these values before model training. First let's look at variable relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "survivors = train_df.loc[train_df['Survived']==True]\n",
    "deceased = train_df.loc[train_df['Survived']==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate each variable's relationship with 'Survived':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      468\n",
       "female     81\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deceased['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    233\n",
       "male      109\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survivors['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "male_deceased = deceased['Sex'].value_counts()[0]\n",
    "male_survived = survivors['Sex'].value_counts()[0]\n",
    "male_total = male_survived + male_deceased\n",
    "male_frac_survived = male_survived/male_total\n",
    "\n",
    "female_deceased = deceased['Sex'].value_counts()[1]\n",
    "female_survived = survivors['Sex'].value_counts()[1]\n",
    "female_total = female_survived + female_deceased\n",
    "female_frac_survived = female_survived/female_total\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar('Male', male_frac_survived, color='r')\n",
    "ax.bar('Female', female_frac_survived, color='b')\n",
    "ax.set_ylabel('Fraction survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender looks like a fairly strong indicator, with women more likely to have survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine other variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = 'Embarked'\n",
    "unique_values = pd.DataFrame(train_df[var].unique())\n",
    "unique_values.dropna(inplace=True)\n",
    "count_data = np.zeros((len(unique_values),3))\n",
    "\n",
    "for series_idx, series in enumerate([deceased, survivors]):\n",
    "    for val_idx, val in enumerate(series[var].unique()):\n",
    "        if val_idx+1 > len(unique_values):\n",
    "            continue\n",
    "        else:\n",
    "            count_data[val_idx, series_idx] = series[var].value_counts().iloc[val_idx]        \n",
    "plot_data = count_data[:,1]/(count_data[:,0]+count_data[:,1])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, cell in enumerate(plot_data):\n",
    "    ax.bar(x=unique_values.iloc[i],height=cell)\n",
    "ax.set_title('Variable: {}'.format(var))\n",
    "ax.set_ylabel('Fraction survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = 'Pclass'\n",
    "unique_values = pd.DataFrame(train_df[var].unique())\n",
    "unique_values.dropna(inplace=True)\n",
    "count_data = np.zeros((len(unique_values),3))\n",
    "\n",
    "for series_idx, series in enumerate([deceased, survivors]):\n",
    "    for val_idx, val in enumerate(series[var].unique()):\n",
    "        if val_idx+1 > len(unique_values):\n",
    "            continue\n",
    "        else:\n",
    "            count_data[val_idx, series_idx] = series[var].value_counts().iloc[val_idx]        \n",
    "plot_data = count_data[:,1]/(count_data[:,0]+count_data[:,1])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, cell in enumerate(plot_data):\n",
    "    ax.bar(x=unique_values.iloc[i],height=cell)\n",
    "ax.set_title('Variable: {}'.format(var))\n",
    "ax.set_ylabel('Fraction survived')\n",
    "ax.set_xticks([1, 2, 3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learnings:\n",
    "\n",
    "- If you are in class 3 you are more likely to have died. If you are in 1, you are more likely to have survived. in 2 it's roughly 50:50\n",
    "- If you embarked at 'C' you are more likely to have survived. Of course, this may be because that more women and children embarked at 'C' in relative terms (or other similar group cross section arguments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the 'Cabin' entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621            D19\n",
      "345            F33\n",
      "183             F4\n",
      "331           C124\n",
      "166            E33\n",
      "215            D36\n",
      "356            E33\n",
      "505            C65\n",
      "27     C23 C25 C27\n",
      "745            B22\n",
      "339              T\n",
      "806            A36\n",
      "849            C92\n",
      "839            C47\n",
      "327              D\n",
      "92             E31\n",
      "248            D35\n",
      "139            B86\n",
      "438    C23 C25 C27\n",
      "194             B4\n",
      "662            E58\n",
      "319            E34\n",
      "366            D37\n",
      "618             F4\n",
      "185            A32\n",
      "Name: Cabin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Cabin'].dropna().sample(n=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     687\n",
      "False    204\n",
      "Name: Cabin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Cabin'].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data entries look very incomplete, let's drop the 'Cabin' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['Cabin'], axis=1, inplace=True)\n",
    "test_df.drop(['Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338                        Dahl, Mr. Karl Edwart\n",
       "22                   McGowan, Miss. Anna \"Annie\"\n",
       "573                            Kelly, Miss. Mary\n",
       "124                  White, Mr. Percival Wayland\n",
       "673                        Wilhelms, Mr. Charles\n",
       "775      Myhrman, Mr. Pehr Fabian Oliver Malkolm\n",
       "634                           Skoog, Miss. Mabel\n",
       "609                    Shutes, Miss. Elizabeth W\n",
       "155                  Williams, Mr. Charles Duane\n",
       "370                  Harder, Mr. George Achilles\n",
       "547                   Padro y Manent, Mr. Julian\n",
       "106             Salkjelsvik, Miss. Anna Kristine\n",
       "406             Widegren, Mr. Carl/Charles Peter\n",
       "341               Fortune, Miss. Alice Elizabeth\n",
       "23                  Sloper, Mr. William Thompson\n",
       "647          Simonius-Blumer, Col. Oberst Alfons\n",
       "760                           Garfirth, Mr. John\n",
       "60                         Sirayanian, Mr. Orsen\n",
       "24                 Palsson, Miss. Torborg Danira\n",
       "736      Ford, Mrs. Edward (Margaret Ann Watson)\n",
       "852                      Boulos, Miss. Nourelain\n",
       "823                           Moor, Mrs. (Beila)\n",
       "772                            Mack, Mrs. (Mary)\n",
       "577    Silvey, Mrs. William Baird (Alice Munger)\n",
       "190                          Pinsky, Mrs. (Rosa)\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Name'].sample(n=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some insight from extracting the titles of the passengers. We can use regular expressions to extract the titles of the passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "train_df['Title'] = \"\"\n",
    "test_df['Title'] = \"\"\n",
    "\n",
    "title_pattern = re.compile(', [A-Za-z]+\\.')\n",
    "for index, row in train_df.iterrows():\n",
    "    title_match = title_pattern.search(row['Name'])\n",
    "    if title_match: \n",
    "        train_df['Title'].loc[index] = title_match.group(0)[2:-1]\n",
    "        \n",
    "for index, row in test_df.iterrows():\n",
    "    title_match = title_pattern.search(row['Name'])\n",
    "    if title_match: \n",
    "        test_df['Title'].loc[index] = title_match.group(0)[2:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Col           2\n",
      "Mlle          2\n",
      "Major         2\n",
      "Jonkheer      1\n",
      "Mme           1\n",
      "Ms            1\n",
      "Lady          1\n",
      "Sir           1\n",
      "Don           1\n",
      "Capt          1\n",
      "              1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = 'Age'\n",
    "survivors_data = survivors[var].dropna()\n",
    "deceased_data = deceased[var].dropna()\n",
    "age_bins = [0, 6, 12, 18, 24, 30, 40, 50, 60, 100]\n",
    "\n",
    "s_cut_data = pd.cut(survivors_data, age_bins)\n",
    "d_cut_data = pd.cut(deceased_data, age_bins)\n",
    "survivor_frac = s_cut_data.value_counts()/(s_cut_data.value_counts()+d_cut_data.value_counts())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, cell in enumerate(survivor_frac):\n",
    "    ax.bar(x=str(survivor_frac.index[i]), height=cell, width=0.8)\n",
    "plt.xticks(rotation=-30)\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_ylabel('Fraction Survived')\n",
    "ax.set_xlabel('{}'.format(var))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infants are more likely to have survived. Interesting that children are less likely to have survived (6 to 12y) relative to the general population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's impute missing values for Age. I expect we can do so by correlating with other variables like Class, Title, SibSp and Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Title')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at correlation between title and age\n",
    "# only consider titles with > 2 entry counts\n",
    "titles = ['Mr', 'Miss', 'Mrs', 'Master', 'Dr', 'Rev']\n",
    "mean_ages = []\n",
    "\n",
    "for title in titles:\n",
    "    mean_ages.append(train_df['Age'].loc[train_df['Title']==title].mean())\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.bar(titles, mean_ages)\n",
    "ax.set_ylabel('Age (years)')\n",
    "ax.set_xlabel('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Class')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at correlation between class and age\n",
    "mean_ages = []\n",
    "\n",
    "for Pclass in train_df['Pclass'].unique():\n",
    "    mean_ages.append(train_df['Age'].loc[train_df['Pclass']==Pclass].mean())\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.bar(train_df['Pclass'].unique(), mean_ages)\n",
    "ax.set_xticks([1, 2, 3])\n",
    "ax.set_ylabel('Age (years)')\n",
    "ax.set_xlabel('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'SibSp')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at correlation between SibSp and age\n",
    "mean_ages = []\n",
    "\n",
    "for SibSp in train_df['SibSp'].unique():\n",
    "    mean_ages.append(train_df['Age'].loc[train_df['SibSp']==SibSp].mean())\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.bar(train_df['SibSp'].unique(), mean_ages)\n",
    "#ax.set_xticks([1, 2, 3])\n",
    "ax.set_ylabel('Age (years)')\n",
    "ax.set_xlabel('SibSp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Parch')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at correlation between Parch and age\n",
    "mean_ages = []\n",
    "\n",
    "for Parch in train_df['Parch'].unique():\n",
    "    mean_ages.append(train_df['Age'].loc[train_df['Parch']==Parch].mean())\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.bar(train_df['Parch'].unique(), mean_ages)\n",
    "ax.set_ylabel('Age (years)')\n",
    "ax.set_xlabel('Parch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute values for age\n",
    "# using means of combinations of class and title\n",
    "\n",
    "age_guess = np.zeros((train_df['Title'].unique().size, train_df['Pclass'].unique().size))\n",
    "for i, title in enumerate(train_df['Title'].unique()):\n",
    "    for j, cls in enumerate(train_df['Pclass'].unique()):\n",
    "        age_guess[i,j] = train_df['Age'].loc[(train_df['Title']==title) & \\\n",
    "                                             (train_df['Pclass']==cls)].mean()\n",
    "        train_df.loc[train_df['Age'].isnull() & (train_df['Title']==title) & \\\n",
    "                     (train_df['Pclass']==cls), 'Age'] = age_guess[i,j]\n",
    "        \n",
    "age_guess = np.zeros((test_df['Title'].unique().size, test_df['Pclass'].unique().size))\n",
    "for i, title in enumerate(test_df['Title'].unique()):\n",
    "    for j, cls in enumerate(test_df['Pclass'].unique()):\n",
    "        age_guess[i,j] = test_df['Age'].loc[(test_df['Title']==title) & \\\n",
    "                                             (test_df['Pclass']==cls)].mean()\n",
    "        test_df.loc[test_df['Age'].isnull() & (test_df['Title']==title) & \\\n",
    "                     (test_df['Pclass']==cls), 'Age'] = age_guess[i,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at the two missing data points for Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Embarked Title  \n",
       "61   female  38.0      0      0  113572  80.0      NaN  Miss  \n",
       "829  female  62.0      0      0  113572  80.0      NaN   Mrs  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the husband (father) is on board for the second entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId                                          830\n",
      "Survived                                               1\n",
      "Pclass                                                 1\n",
      "Name           Stone, Mrs. George Nelson (Martha Evelyn)\n",
      "Sex                                               female\n",
      "Age                                                   62\n",
      "SibSp                                                  0\n",
      "Parch                                                  0\n",
      "Ticket                                            113572\n",
      "Fare                                                  80\n",
      "Embarked                                             NaN\n",
      "Title                                                Mrs\n",
      "Name: 829, dtype: object\n"
     ]
    }
   ],
   "source": [
    "name_string = re.compile('George Nelson')\n",
    "for index, row in train_df.iterrows():\n",
    "    name_match = name_string.search(row['Name'])\n",
    "    if name_match:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He's not, which doesn't help with imputing the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sunderland, Mr. Victor Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392089</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cunningham, Mr. Alfred Fleming</td>\n",
       "      <td>male</td>\n",
       "      <td>32.768293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hendekovic, Mr. Ignjac</td>\n",
       "      <td>male</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349243</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>16.123188</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>665</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Lindqvist, Mr. Eino William</td>\n",
       "      <td>male</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101285</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mineff, Mr. Ivan</td>\n",
       "      <td>male</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349233</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>513</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>McGough, Mr. James Robert</td>\n",
       "      <td>male</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17473</td>\n",
       "      <td>26.2875</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>441</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hart, Mrs. Benjamin (Esther Ada Bloomfield)</td>\n",
       "      <td>female</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F.C.C. 13529</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>832</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Richards, Master. George Sibley</td>\n",
       "      <td>male</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29106</td>\n",
       "      <td>18.7500</td>\n",
       "      <td>S</td>\n",
       "      <td>Master</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Downton, Mr. William James</td>\n",
       "      <td>male</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28403</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>28.724891</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Miss. Alice Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Shellard, Mr. Frederick William</td>\n",
       "      <td>male</td>\n",
       "      <td>28.724891</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 6212</td>\n",
       "      <td>15.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>759</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Theobald, Mr. Thomas Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363294</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sdycoff, Mr. Todor</td>\n",
       "      <td>male</td>\n",
       "      <td>28.724891</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349222</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "220          221         1       3   \n",
       "413          414         0       2   \n",
       "313          314         0       3   \n",
       "863          864         0       3   \n",
       "664          665         1       3   \n",
       "294          295         0       3   \n",
       "512          513         1       1   \n",
       "440          441         1       2   \n",
       "831          832         1       2   \n",
       "582          583         0       2   \n",
       "29            30         0       3   \n",
       "341          342         1       1   \n",
       "497          498         0       3   \n",
       "758          759         0       3   \n",
       "410          411         0       3   \n",
       "\n",
       "                                            Name     Sex        Age  SibSp  \\\n",
       "220               Sunderland, Mr. Victor Francis    male  16.000000      0   \n",
       "413               Cunningham, Mr. Alfred Fleming    male  32.768293      0   \n",
       "313                       Hendekovic, Mr. Ignjac    male  28.000000      0   \n",
       "863            Sage, Miss. Dorothy Edith \"Dolly\"  female  16.123188      8   \n",
       "664                  Lindqvist, Mr. Eino William    male  20.000000      1   \n",
       "294                             Mineff, Mr. Ivan    male  24.000000      0   \n",
       "512                    McGough, Mr. James Robert    male  36.000000      0   \n",
       "440  Hart, Mrs. Benjamin (Esther Ada Bloomfield)  female  45.000000      1   \n",
       "831              Richards, Master. George Sibley    male   0.830000      1   \n",
       "582                   Downton, Mr. William James    male  54.000000      0   \n",
       "29                           Todoroff, Mr. Lalio    male  28.724891      0   \n",
       "341               Fortune, Miss. Alice Elizabeth  female  24.000000      3   \n",
       "497              Shellard, Mr. Frederick William    male  28.724891      0   \n",
       "758                 Theobald, Mr. Thomas Leonard    male  34.000000      0   \n",
       "410                           Sdycoff, Mr. Todor    male  28.724891      0   \n",
       "\n",
       "     Parch             Ticket      Fare Embarked   Title  \n",
       "220      0    SOTON/OQ 392089    8.0500        S      Mr  \n",
       "413      0             239853    0.0000        S      Mr  \n",
       "313      0             349243    7.8958        S      Mr  \n",
       "863      2           CA. 2343   69.5500        S    Miss  \n",
       "664      0  STON/O 2. 3101285    7.9250        S      Mr  \n",
       "294      0             349233    7.8958        S      Mr  \n",
       "512      0           PC 17473   26.2875        S      Mr  \n",
       "440      1       F.C.C. 13529   26.2500        S     Mrs  \n",
       "831      1              29106   18.7500        S  Master  \n",
       "582      0              28403   26.0000        S      Mr  \n",
       "29       0             349216    7.8958        S      Mr  \n",
       "341      2              19950  263.0000        S    Miss  \n",
       "497      0          C.A. 6212   15.1000        S      Mr  \n",
       "758      0             363294    8.0500        S      Mr  \n",
       "410      0             349222    7.8958        S      Mr  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df['Embarked'] == 'S'].sample(n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume they departed from Southampton. There doesn't appear to be a strong correlation between other variables and departure port, nor would we expect there to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Embarked'].isnull(), 'Embarked'] = 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Embarked       891 non-null object\n",
      "Title          891 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One feature that could be revealing is a lady's marital status. Let's use regular expressions to create this column of data. We can always drop columns later on if they appear irrelevant or detrimental to model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Married female counts\n",
      "Perished: 18\n",
      "Survived: 63\n",
      "\n",
      "Single female counts\n",
      "Perished: 26\n",
      "Survived: 33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "married = re.compile(r'Mrs.')\n",
    "single = re.compile(r'Miss')\n",
    "death_count = {'single': 0, 'married': 0}\n",
    "survivor_count = {'single': 0, 'married': 0}\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    married_mo = married.search(row['Name'])\n",
    "    single_mo = single.search(row['Name'])\n",
    "    if married_mo and row['SibSp']!=0 and row['Survived']==False:\n",
    "        death_count['married'] += 1\n",
    "    if married_mo and row['SibSp']!=0 and row['Survived']==True:\n",
    "        survivor_count['married'] += 1\n",
    "    if single_mo and row['SibSp']!=0 and row['Survived']==False:\n",
    "        death_count['single'] += 1\n",
    "    if single_mo and row['SibSp']!=0 and row['Survived']==True:\n",
    "        survivor_count['single'] += 1\n",
    "\n",
    "print(\"Married female counts\")\n",
    "print(\"Perished: \" + str(death_count['married']))\n",
    "print(\"Survived: \" + str(survivor_count['married']) + \"\\n\")\n",
    "print(\"Single female counts\")\n",
    "print(\"Perished: \" + str(death_count['single']))\n",
    "print(\"Survived: \" + str(survivor_count['single']) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single female survived ratio is similar to the overall for females (50 to 60%), but reasonably higher for females who are married but alone. Let's create PartySize and IsAlone variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['PartySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
    "train_df['IsAlone'] = 0\n",
    "train_df.loc[train_df['PartySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "test_df['PartySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
    "test_df['IsAlone'] = 0\n",
    "test_df.loc[test_df['PartySize'] == 1, 'IsAlone'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Embarked       891 non-null object\n",
      "Title          891 non-null object\n",
      "PartySize      891 non-null int64\n",
      "IsAlone        891 non-null int64\n",
      "dtypes: float64(2), int64(7), object(5)\n",
      "memory usage: 97.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Ticket, Name and Id from the train dataset, as these are unique for each passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['Ticket', 'Name', 'PassengerId'], axis=1, inplace=True)\n",
    "test_df.drop(['Ticket', 'Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "Survived     891 non-null int64\n",
      "Pclass       891 non-null int64\n",
      "Sex          891 non-null object\n",
      "Age          891 non-null float64\n",
      "SibSp        891 non-null int64\n",
      "Parch        891 non-null int64\n",
      "Fare         891 non-null float64\n",
      "Embarked     891 non-null object\n",
      "Title        891 non-null object\n",
      "PartySize    891 non-null int64\n",
      "IsAlone      891 non-null int64\n",
      "dtypes: float64(2), int64(6), object(3)\n",
      "memory usage: 76.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Sex            418 non-null object\n",
      "Age            417 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Fare           417 non-null float64\n",
      "Embarked       418 non-null object\n",
      "Title          418 non-null object\n",
      "PartySize      418 non-null int64\n",
      "IsAlone        418 non-null int64\n",
      "dtypes: float64(2), int64(6), object(3)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to impute missing value for age and fare in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>PartySize</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>980</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>Q</td>\n",
       "      <td>Ms</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Pclass     Sex  Age  SibSp  Parch  Fare Embarked Title  \\\n",
       "88          980       3  female  NaN      0      0  7.75        Q    Ms   \n",
       "\n",
       "    PartySize  IsAlone  \n",
       "88          1        1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['Age'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low fare, low class, title Ms and is alone suggests a young woman. (c. 20). Let's see if there are any comparators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>PartySize</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Ms</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch  Fare Embarked Title  \\\n",
       "443         1       2  female  28.0      0      0  13.0        S    Ms   \n",
       "\n",
       "     PartySize  IsAlone  \n",
       "443          1        1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df['Title']=='Ms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also set her Age to 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['Age'].isnull(), 'Age'] = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the missing Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>PartySize</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass   Sex   Age  SibSp  Parch  Fare Embarked Title  \\\n",
       "152         1044       3  male  60.5      0      0   NaN        S    Mr   \n",
       "\n",
       "     PartySize  IsAlone  \n",
       "152          1        1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['Fare'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class is likely to be the largest determinant of Fare, let's set Fare to the median of this group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[test_df['Fare'].isnull(), 'Fare'] = train_df.loc[train_df['Pclass']==3, 'Fare'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Sex            418 non-null object\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Fare           418 non-null float64\n",
      "Embarked       418 non-null object\n",
      "Title          418 non-null object\n",
      "PartySize      418 non-null int64\n",
      "IsAlone        418 non-null int64\n",
      "dtypes: float64(2), int64(6), object(3)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df)\n",
    "test_df = pd.get_dummies(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>PartySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Major</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  PartySize  IsAlone  \\\n",
       "0         0       3  22.0      1      0   7.2500          2        0   \n",
       "1         1       1  38.0      1      0  71.2833          2        0   \n",
       "2         1       3  26.0      0      0   7.9250          1        1   \n",
       "3         1       1  35.0      1      0  53.1000          2        0   \n",
       "4         0       3  35.0      0      0   8.0500          1        1   \n",
       "\n",
       "   Sex_female  Sex_male  ...  Title_Major  Title_Master  Title_Miss  \\\n",
       "0           0         1  ...            0             0           0   \n",
       "1           1         0  ...            0             0           0   \n",
       "2           1         0  ...            0             0           1   \n",
       "3           1         0  ...            0             0           0   \n",
       "4           0         1  ...            0             0           0   \n",
       "\n",
       "   Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  Title_Sir  \n",
       "0           0          0         1          0         0          0          0  \n",
       "1           0          0         0          1         0          0          0  \n",
       "2           0          0         0          0         0          0          0  \n",
       "3           0          0         0          1         0          0          0  \n",
       "4           0          0         1          0         0          0          0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>PartySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Col</th>\n",
       "      <th>Title_Dona</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Age  SibSp  Parch     Fare  PartySize  IsAlone  \\\n",
       "0          892       3  34.5      0      0   7.8292          1        1   \n",
       "1          893       3  47.0      1      0   7.0000          2        0   \n",
       "2          894       2  62.0      0      0   9.6875          1        1   \n",
       "3          895       3  27.0      0      0   8.6625          1        1   \n",
       "4          896       3  22.0      1      1  12.2875          3        0   \n",
       "\n",
       "   Sex_female  Sex_male  ...  Embarked_S  Title_Col  Title_Dona  Title_Dr  \\\n",
       "0           0         1  ...           0          0           0         0   \n",
       "1           1         0  ...           1          0           0         0   \n",
       "2           0         1  ...           0          0           0         0   \n",
       "3           0         1  ...           1          0           0         0   \n",
       "4           1         0  ...           1          0           0         0   \n",
       "\n",
       "   Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Ms  Title_Rev  \n",
       "0             0           0         1          0         0          0  \n",
       "1             0           0         0          1         0          0  \n",
       "2             0           0         1          0         0          0  \n",
       "3             0           0         1          0         0          0  \n",
       "4             0           0         0          1         0          0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some titles only appear in the train dataset and some only appear in the test dataset. Both should contain the same independent variables (columns) so we need to drop or impute values to allow any model to predict the test dataset's 'Survived' variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_col in train_df.columns:\n",
    "    present = False\n",
    "    for test_col in test_df.columns:\n",
    "        if test_col == train_col:\n",
    "            present = True\n",
    "    if not present and train_col != 'Survived':\n",
    "        test_df[train_col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId\n",
      "Title_Dona\n"
     ]
    }
   ],
   "source": [
    "for test_col in test_df.columns:\n",
    "    present = False\n",
    "    for train_col in train_df.columns:\n",
    "        if train_col == test_col:\n",
    "            present = True\n",
    "    if not present:\n",
    "        print(test_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(['Title_Dona'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['Survived'], axis=1)\n",
    "y_train = train_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835016835016835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrm = LogisticRegression(solver='newton-cg')\n",
    "lrm.fit(X_train, y_train)\n",
    "print(lrm.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic logistic regression model would be c. top 5% on the Kaggle leaderboard if the model generalises well, which is a good start!\n",
    "\n",
    "Let's look at the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-02da47c88dc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoeff\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlrm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\": \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"{:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoeff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "for var, coeff in zip(x.columns, lrm.coef_[0]):\n",
    "    print(var + \" \"*(15-len(var)) + \": \" + \"{:.2f}\".format(coeff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex, class and some titles look like reasonably strong determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at some other models, to see hwo they perform:\n",
    "- KNN\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Gradient Boosting Classifier\n",
    "- SVM\n",
    "- NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def ModelGridSearch(model, parameters):\n",
    "    clf = GridSearchCV(estimator=model, param_grid=parameters, cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    results = pd.DataFrame(clf.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results = ModelGridSearch(KNeighborsClassifier(), {'n_neighbors': [1, 2, 3, 4, 5], \n",
    "                                         'weights': ['uniform', 'distance'], \n",
    "                                         'p': [1,2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 4, 'p': 1, 'weights': 'distance'}</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.731844</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.762065</td>\n",
       "      <td>0.018718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.021605</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 4, 'p': 1, 'weights': 'uniform'}</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.751412</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.731844</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.755331</td>\n",
       "      <td>0.019870</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 3, 'p': 1, 'weights': 'distance'}</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.750842</td>\n",
       "      <td>0.019846</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 5, 'p': 1, 'weights': 'distance'}</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.747191</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.746352</td>\n",
       "      <td>0.016075</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 4, 'p': 2, 'weights': 'distance'}</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.720670</td>\n",
       "      <td>0.747191</td>\n",
       "      <td>0.713483</td>\n",
       "      <td>0.757062</td>\n",
       "      <td>0.732884</td>\n",
       "      <td>0.016462</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}</td>\n",
       "      <td>0.731844</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.731762</td>\n",
       "      <td>0.012576</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 2, 'p': 1, 'weights': 'uniform'}</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.724719</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.026082</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 2, 'p': 1, 'weights': 'distance'}</td>\n",
       "      <td>0.715084</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.726150</td>\n",
       "      <td>0.025545</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 3, 'p': 2, 'weights': 'distance'}</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.713483</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.725028</td>\n",
       "      <td>0.012901</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}</td>\n",
       "      <td>0.703911</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.718294</td>\n",
       "      <td>0.025782</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 1, 'p': 1, 'weights': 'distance'}</td>\n",
       "      <td>0.703911</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.718294</td>\n",
       "      <td>0.025782</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 5, 'p': 2, 'weights': 'distance'}</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.735955</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.734463</td>\n",
       "      <td>0.718294</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.724719</td>\n",
       "      <td>0.747191</td>\n",
       "      <td>0.734463</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.026501</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 4, 'p': 2, 'weights': 'uniform'}</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>0.715084</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.713483</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.712682</td>\n",
       "      <td>0.015888</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 2, 'p': 2, 'weights': 'distance'}</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.724719</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.689266</td>\n",
       "      <td>0.705948</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 2, 'p': 2, 'weights': 'uniform'}</td>\n",
       "      <td>0.715084</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.689266</td>\n",
       "      <td>0.699214</td>\n",
       "      <td>0.009047</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 1, 'p': 2, 'weights': 'distance'}</td>\n",
       "      <td>0.687151</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.691011</td>\n",
       "      <td>0.689266</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}</td>\n",
       "      <td>0.687151</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.691011</td>\n",
       "      <td>0.689266</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "13       0.001610      0.003219         0.004053        0.004248   \n",
       "8        0.001613      0.003226         0.008508        0.003228   \n",
       "12       0.000402      0.000805         0.005263        0.004362   \n",
       "16       0.003861      0.002265         0.006469        0.000452   \n",
       "9        0.003222      0.003946         0.000820        0.001004   \n",
       "17       0.002410      0.000812         0.002576        0.000493   \n",
       "15       0.003048      0.003751         0.001025        0.001295   \n",
       "10       0.001001      0.001265         0.008954        0.003582   \n",
       "4        0.001968      0.002710         0.008448        0.005874   \n",
       "5        0.002034      0.000076         0.002399        0.000483   \n",
       "11       0.002240      0.000394         0.002038        0.001097   \n",
       "0        0.001864      0.001005         0.005009        0.002529   \n",
       "1        0.002404      0.000515         0.001978        0.000631   \n",
       "19       0.003230      0.003956         0.000822        0.001007   \n",
       "18       0.000800      0.000980         0.007455        0.002201   \n",
       "14       0.003633      0.003687         0.004860        0.004344   \n",
       "7        0.001208      0.000987         0.002010        0.002776   \n",
       "6        0.002595      0.000492         0.006425        0.000456   \n",
       "3        0.000000      0.000000         0.003132        0.006263   \n",
       "2        0.001995      0.002185         0.006533        0.005060   \n",
       "\n",
       "   param_n_neighbors param_p param_weights  \\\n",
       "13                 4       1      distance   \n",
       "8                  3       1       uniform   \n",
       "12                 4       1       uniform   \n",
       "16                 5       1       uniform   \n",
       "9                  3       1      distance   \n",
       "17                 5       1      distance   \n",
       "15                 4       2      distance   \n",
       "10                 3       2       uniform   \n",
       "4                  2       1       uniform   \n",
       "5                  2       1      distance   \n",
       "11                 3       2      distance   \n",
       "0                  1       1       uniform   \n",
       "1                  1       1      distance   \n",
       "19                 5       2      distance   \n",
       "18                 5       2       uniform   \n",
       "14                 4       2       uniform   \n",
       "7                  2       2      distance   \n",
       "6                  2       2       uniform   \n",
       "3                  1       2      distance   \n",
       "2                  1       2       uniform   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "13  {'n_neighbors': 4, 'p': 1, 'weights': 'distance'}           0.754190   \n",
       "8    {'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}           0.737430   \n",
       "12   {'n_neighbors': 4, 'p': 1, 'weights': 'uniform'}           0.748603   \n",
       "16   {'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}           0.743017   \n",
       "9   {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}           0.743017   \n",
       "17  {'n_neighbors': 5, 'p': 1, 'weights': 'distance'}           0.743017   \n",
       "15  {'n_neighbors': 4, 'p': 2, 'weights': 'distance'}           0.726257   \n",
       "10   {'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}           0.731844   \n",
       "4    {'n_neighbors': 2, 'p': 1, 'weights': 'uniform'}           0.743017   \n",
       "5   {'n_neighbors': 2, 'p': 1, 'weights': 'distance'}           0.715084   \n",
       "11  {'n_neighbors': 3, 'p': 2, 'weights': 'distance'}           0.726257   \n",
       "0    {'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}           0.703911   \n",
       "1   {'n_neighbors': 1, 'p': 1, 'weights': 'distance'}           0.703911   \n",
       "19  {'n_neighbors': 5, 'p': 2, 'weights': 'distance'}           0.692737   \n",
       "18   {'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}           0.670391   \n",
       "14   {'n_neighbors': 4, 'p': 2, 'weights': 'uniform'}           0.692737   \n",
       "7   {'n_neighbors': 2, 'p': 2, 'weights': 'distance'}           0.692737   \n",
       "6    {'n_neighbors': 2, 'p': 2, 'weights': 'uniform'}           0.715084   \n",
       "3   {'n_neighbors': 1, 'p': 2, 'weights': 'distance'}           0.687151   \n",
       "2    {'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}           0.687151   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "13           0.731844           0.786517           0.775281   \n",
       "8            0.737430           0.780899           0.786517   \n",
       "12           0.748603           0.769663           0.769663   \n",
       "16           0.731844           0.769663           0.786517   \n",
       "9            0.726257           0.786517           0.752809   \n",
       "17           0.726257           0.775281           0.747191   \n",
       "15           0.720670           0.747191           0.713483   \n",
       "10           0.709497           0.741573           0.730337   \n",
       "4            0.709497           0.769663           0.724719   \n",
       "5            0.726257           0.775281           0.707865   \n",
       "11           0.709497           0.730337           0.713483   \n",
       "0            0.709497           0.769663           0.702247   \n",
       "1            0.709497           0.769663           0.702247   \n",
       "19           0.709497           0.735955           0.719101   \n",
       "18           0.709497           0.724719           0.747191   \n",
       "14           0.715084           0.702247           0.713483   \n",
       "7            0.726257           0.724719           0.696629   \n",
       "6            0.692737           0.702247           0.696629   \n",
       "3            0.698324           0.719101           0.691011   \n",
       "2            0.698324           0.719101           0.691011   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "13           0.762712         0.762065        0.018718                1  \n",
       "8            0.745763         0.757576        0.021605                2  \n",
       "12           0.751412         0.757576        0.009913                2  \n",
       "16           0.745763         0.755331        0.019870                4  \n",
       "9            0.745763         0.750842        0.019846                5  \n",
       "17           0.740113         0.746352        0.016075                6  \n",
       "15           0.757062         0.732884        0.016462                7  \n",
       "10           0.745763         0.731762        0.012576                8  \n",
       "4            0.694915         0.728395        0.026082                9  \n",
       "5            0.706215         0.726150        0.025545               10  \n",
       "11           0.745763         0.725028        0.012901               11  \n",
       "0            0.706215         0.718294        0.025782               12  \n",
       "1            0.706215         0.718294        0.025782               12  \n",
       "19           0.734463         0.718294        0.016160               12  \n",
       "18           0.734463         0.717172        0.026501               15  \n",
       "14           0.740113         0.712682        0.015888               16  \n",
       "7            0.689266         0.705948        0.016154               17  \n",
       "6            0.689266         0.699214        0.009047               18  \n",
       "3            0.689266         0.696970        0.011682               19  \n",
       "2            0.689266         0.696970        0.011682               19  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results = ModelGridSearch(DecisionTreeClassifier(), {'max_depth': [1, 2, 3, 4, 5],\n",
    "                                           'min_samples_leaf': [1, 2, 3],\n",
    "                                           'criterion': ['gini', 'entropy'],\n",
    "                                           'splitter': ['best', 'random']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'min_...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.837262</td>\n",
       "      <td>0.023968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'min_...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'min_...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'min_...</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.022923</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.865922</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.824916</td>\n",
       "      <td>0.028382</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'min_...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.823793</td>\n",
       "      <td>0.020507</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'min_sam...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.026518</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.014058</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'min_...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.018555</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.032173</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'min_...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.019879</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.021597</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'min_...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.019879</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.836158</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.004070</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'min_sam...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.017660</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'min_sam...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.017660</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.023081</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'min_sam...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.017660</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.836158</td>\n",
       "      <td>0.811448</td>\n",
       "      <td>0.022474</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.811448</td>\n",
       "      <td>0.019829</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.809203</td>\n",
       "      <td>0.022242</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 4, 'min_sam...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.809203</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'min_...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>0.015495</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'min_sam...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.803591</td>\n",
       "      <td>0.026221</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'min_...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.836158</td>\n",
       "      <td>0.800224</td>\n",
       "      <td>0.030308</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.018128</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.015579</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 4, 'min_...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.026740</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 3, 'min_sam...</td>\n",
       "      <td>0.715084</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.793490</td>\n",
       "      <td>0.043458</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.021709</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.022093</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 3, 'min_...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.807910</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.022724</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.022045</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.022045</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.022045</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.784512</td>\n",
       "      <td>0.018494</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 2, 'min_...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.784512</td>\n",
       "      <td>0.018636</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.783389</td>\n",
       "      <td>0.025401</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.003224</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.026576</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.006236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.026576</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.026576</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 2, 'min_sam...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.781145</td>\n",
       "      <td>0.011812</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "48       0.002651      0.000545         0.000598        0.000489   \n",
       "50       0.002034      0.002630         0.000587        0.000810   \n",
       "52       0.002016      0.003110         0.000000        0.000000   \n",
       "49       0.002208      0.000410         0.000584        0.000477   \n",
       "27       0.002024      0.003122         0.000000        0.000000   \n",
       "53       0.003631      0.003687         0.000000        0.000000   \n",
       "17       0.002036      0.003146         0.000000        0.000000   \n",
       "55       0.001972      0.001831         0.002197        0.002951   \n",
       "42       0.003226      0.003946         0.000000        0.000000   \n",
       "25       0.002025      0.003125         0.002028        0.003122   \n",
       "44       0.000814      0.000997         0.001801        0.003142   \n",
       "22       0.002655      0.000546         0.000785        0.000393   \n",
       "46       0.004063      0.003171         0.000597        0.000488   \n",
       "21       0.001008      0.001270         0.003474        0.003850   \n",
       "20       0.002613      0.002943         0.001489        0.001602   \n",
       "19       0.000409      0.000819         0.001610        0.003220   \n",
       "18       0.004070      0.003338         0.000006        0.000012   \n",
       "59       0.001588      0.000794         0.001052        0.000648   \n",
       "16       0.004423      0.005742         0.000823        0.001008   \n",
       "14       0.002203      0.000392         0.000798        0.000399   \n",
       "57       0.002391      0.000493         0.000801        0.000401   \n",
       "12       0.002603      0.000479         0.000979        0.000020   \n",
       "29       0.002026      0.003125         0.000000        0.000000   \n",
       "54       0.003635      0.003692         0.000409        0.000818   \n",
       "56       0.002277      0.003617         0.001611        0.002751   \n",
       "23       0.002190      0.000409         0.001002        0.000018   \n",
       "58       0.002992      0.000021         0.000990        0.000012   \n",
       "47       0.001998      0.000015         0.001186        0.000391   \n",
       "15       0.000822      0.001008         0.000199        0.000399   \n",
       "43       0.000820      0.001004         0.001620        0.003239   \n",
       "24       0.002036      0.001097         0.000598        0.000488   \n",
       "28       0.003232      0.003958         0.000402        0.000805   \n",
       "51       0.003225      0.003949         0.000411        0.000821   \n",
       "26       0.002024      0.004048         0.000000        0.000000   \n",
       "13       0.001604      0.000496         0.000827        0.000418   \n",
       "7        0.003125      0.006250         0.000000        0.000000   \n",
       "37       0.001995      0.000003         0.000200        0.000399   \n",
       "45       0.000411      0.000822         0.000000        0.000000   \n",
       "36       0.002602      0.000515         0.001005        0.000643   \n",
       "38       0.002409      0.002960         0.000200        0.000399   \n",
       "40       0.003225      0.003950         0.000000        0.000000   \n",
       "39       0.000813      0.000996         0.000000        0.000000   \n",
       "41       0.002021      0.003120         0.000410        0.000820   \n",
       "9        0.002976      0.002627         0.000592        0.000483   \n",
       "30       0.002025      0.003124         0.001612        0.003224   \n",
       "35       0.002437      0.000461         0.001553        0.000461   \n",
       "34       0.002876      0.002818         0.000589        0.000481   \n",
       "33       0.001629      0.001023         0.000811        0.000769   \n",
       "32       0.002814      0.002728         0.000924        0.000960   \n",
       "31       0.000414      0.000822         0.000412        0.000824   \n",
       "10       0.000723      0.000900         0.000000        0.000000   \n",
       "8        0.003118      0.006236         0.000000        0.000000   \n",
       "6        0.000000      0.000000         0.003132        0.006264   \n",
       "11       0.001611      0.000806         0.003789        0.006112   \n",
       "1        0.002200      0.000393         0.000799        0.000399   \n",
       "5        0.001215      0.000765         0.000597        0.000487   \n",
       "4        0.001989      0.000014         0.000797        0.000399   \n",
       "3        0.001994      0.000620         0.000876        0.000453   \n",
       "2        0.002030      0.000088         0.000599        0.000489   \n",
       "0        0.003656      0.001509         0.001198        0.000400   \n",
       "\n",
       "   param_criterion param_max_depth param_min_samples_leaf param_splitter  \\\n",
       "48         entropy               4                      1           best   \n",
       "50         entropy               4                      2           best   \n",
       "52         entropy               4                      3           best   \n",
       "49         entropy               4                      1         random   \n",
       "27            gini               5                      2         random   \n",
       "53         entropy               4                      3         random   \n",
       "17            gini               3                      3         random   \n",
       "55         entropy               5                      1         random   \n",
       "42         entropy               3                      1           best   \n",
       "25            gini               5                      1         random   \n",
       "44         entropy               3                      2           best   \n",
       "22            gini               4                      3           best   \n",
       "46         entropy               3                      3           best   \n",
       "21            gini               4                      2         random   \n",
       "20            gini               4                      2           best   \n",
       "19            gini               4                      1         random   \n",
       "18            gini               4                      1           best   \n",
       "59         entropy               5                      3         random   \n",
       "16            gini               3                      3           best   \n",
       "14            gini               3                      2           best   \n",
       "57         entropy               5                      2         random   \n",
       "12            gini               3                      1           best   \n",
       "29            gini               5                      3         random   \n",
       "54         entropy               5                      1           best   \n",
       "56         entropy               5                      2           best   \n",
       "23            gini               4                      3         random   \n",
       "58         entropy               5                      3           best   \n",
       "47         entropy               3                      3         random   \n",
       "15            gini               3                      2         random   \n",
       "43         entropy               3                      1         random   \n",
       "24            gini               5                      1           best   \n",
       "28            gini               5                      3           best   \n",
       "51         entropy               4                      2         random   \n",
       "26            gini               5                      2           best   \n",
       "13            gini               3                      1         random   \n",
       "7             gini               2                      1         random   \n",
       "37         entropy               2                      1         random   \n",
       "45         entropy               3                      2         random   \n",
       "36         entropy               2                      1           best   \n",
       "38         entropy               2                      2           best   \n",
       "40         entropy               2                      3           best   \n",
       "39         entropy               2                      2         random   \n",
       "41         entropy               2                      3         random   \n",
       "9             gini               2                      2         random   \n",
       "30         entropy               1                      1           best   \n",
       "35         entropy               1                      3         random   \n",
       "34         entropy               1                      3           best   \n",
       "33         entropy               1                      2         random   \n",
       "32         entropy               1                      2           best   \n",
       "31         entropy               1                      1         random   \n",
       "10            gini               2                      3           best   \n",
       "8             gini               2                      2           best   \n",
       "6             gini               2                      1           best   \n",
       "11            gini               2                      3         random   \n",
       "1             gini               1                      1         random   \n",
       "5             gini               1                      3         random   \n",
       "4             gini               1                      3           best   \n",
       "3             gini               1                      2         random   \n",
       "2             gini               1                      2           best   \n",
       "0             gini               1                      1           best   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "48  {'criterion': 'entropy', 'max_depth': 4, 'min_...           0.843575   \n",
       "50  {'criterion': 'entropy', 'max_depth': 4, 'min_...           0.843575   \n",
       "52  {'criterion': 'entropy', 'max_depth': 4, 'min_...           0.843575   \n",
       "49  {'criterion': 'entropy', 'max_depth': 4, 'min_...           0.860335   \n",
       "27  {'criterion': 'gini', 'max_depth': 5, 'min_sam...           0.865922   \n",
       "53  {'criterion': 'entropy', 'max_depth': 4, 'min_...           0.849162   \n",
       "17  {'criterion': 'gini', 'max_depth': 3, 'min_sam...           0.837989   \n",
       "55  {'criterion': 'entropy', 'max_depth': 5, 'min_...           0.832402   \n",
       "42  {'criterion': 'entropy', 'max_depth': 3, 'min_...           0.826816   \n",
       "25  {'criterion': 'gini', 'max_depth': 5, 'min_sam...           0.849162   \n",
       "44  {'criterion': 'entropy', 'max_depth': 3, 'min_...           0.826816   \n",
       "22  {'criterion': 'gini', 'max_depth': 4, 'min_sam...           0.843575   \n",
       "46  {'criterion': 'entropy', 'max_depth': 3, 'min_...           0.826816   \n",
       "21  {'criterion': 'gini', 'max_depth': 4, 'min_sam...           0.810056   \n",
       "20  {'criterion': 'gini', 'max_depth': 4, 'min_sam...           0.837989   \n",
       "19  {'criterion': 'gini', 'max_depth': 4, 'min_sam...           0.815642   \n",
       "18  {'criterion': 'gini', 'max_depth': 4, 'min_sam...           0.837989   \n",
       "59  {'criterion': 'entropy', 'max_depth': 5, 'min_...           0.804469   \n",
       "16  {'criterion': 'gini', 'max_depth': 3, 'min_sam...           0.826816   \n",
       "14  {'criterion': 'gini', 'max_depth': 3, 'min_sam...           0.826816   \n",
       "57  {'criterion': 'entropy', 'max_depth': 5, 'min_...           0.815642   \n",
       "12  {'criterion': 'gini', 'max_depth': 3, 'min_sam...           0.826816   \n",
       "29  {'criterion': 'gini', 'max_depth': 5, 'min_sam...           0.821229   \n",
       "54  {'criterion': 'entropy', 'max_depth': 5, 'min_...           0.793296   \n",
       "56  {'criterion': 'entropy', 'max_depth': 5, 'min_...           0.782123   \n",
       "23  {'criterion': 'gini', 'max_depth': 4, 'min_sam...           0.815642   \n",
       "58  {'criterion': 'entropy', 'max_depth': 5, 'min_...           0.782123   \n",
       "47  {'criterion': 'entropy', 'max_depth': 3, 'min_...           0.826816   \n",
       "15  {'criterion': 'gini', 'max_depth': 3, 'min_sam...           0.837989   \n",
       "43  {'criterion': 'entropy', 'max_depth': 3, 'min_...           0.748603   \n",
       "24  {'criterion': 'gini', 'max_depth': 5, 'min_sam...           0.798883   \n",
       "28  {'criterion': 'gini', 'max_depth': 5, 'min_sam...           0.787709   \n",
       "51  {'criterion': 'entropy', 'max_depth': 4, 'min_...           0.787709   \n",
       "26  {'criterion': 'gini', 'max_depth': 5, 'min_sam...           0.782123   \n",
       "13  {'criterion': 'gini', 'max_depth': 3, 'min_sam...           0.715084   \n",
       "7   {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.782123   \n",
       "37  {'criterion': 'entropy', 'max_depth': 2, 'min_...           0.748603   \n",
       "45  {'criterion': 'entropy', 'max_depth': 3, 'min_...           0.748603   \n",
       "36  {'criterion': 'entropy', 'max_depth': 2, 'min_...           0.748603   \n",
       "38  {'criterion': 'entropy', 'max_depth': 2, 'min_...           0.748603   \n",
       "40  {'criterion': 'entropy', 'max_depth': 2, 'min_...           0.748603   \n",
       "39  {'criterion': 'entropy', 'max_depth': 2, 'min_...           0.748603   \n",
       "41  {'criterion': 'entropy', 'max_depth': 2, 'min_...           0.748603   \n",
       "9   {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.748603   \n",
       "30  {'criterion': 'entropy', 'max_depth': 1, 'min_...           0.782123   \n",
       "35  {'criterion': 'entropy', 'max_depth': 1, 'min_...           0.782123   \n",
       "34  {'criterion': 'entropy', 'max_depth': 1, 'min_...           0.782123   \n",
       "33  {'criterion': 'entropy', 'max_depth': 1, 'min_...           0.782123   \n",
       "32  {'criterion': 'entropy', 'max_depth': 1, 'min_...           0.782123   \n",
       "31  {'criterion': 'entropy', 'max_depth': 1, 'min_...           0.782123   \n",
       "10  {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.748603   \n",
       "8   {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.748603   \n",
       "6   {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.748603   \n",
       "11  {'criterion': 'gini', 'max_depth': 2, 'min_sam...           0.782123   \n",
       "1   {'criterion': 'gini', 'max_depth': 1, 'min_sam...           0.782123   \n",
       "5   {'criterion': 'gini', 'max_depth': 1, 'min_sam...           0.782123   \n",
       "4   {'criterion': 'gini', 'max_depth': 1, 'min_sam...           0.782123   \n",
       "3   {'criterion': 'gini', 'max_depth': 1, 'min_sam...           0.782123   \n",
       "2   {'criterion': 'gini', 'max_depth': 1, 'min_sam...           0.782123   \n",
       "0   {'criterion': 'gini', 'max_depth': 1, 'min_sam...           0.782123   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "48           0.821229           0.825843           0.814607   \n",
       "50           0.821229           0.825843           0.814607   \n",
       "52           0.821229           0.825843           0.814607   \n",
       "49           0.821229           0.820225           0.792135   \n",
       "27           0.821229           0.814607           0.780899   \n",
       "53           0.815642           0.803371           0.803371   \n",
       "17           0.787709           0.837079           0.792135   \n",
       "55           0.810056           0.831461           0.797753   \n",
       "42           0.798883           0.820225           0.797753   \n",
       "25           0.810056           0.792135           0.775281   \n",
       "44           0.798883           0.820225           0.792135   \n",
       "22           0.798883           0.808989           0.792135   \n",
       "46           0.798883           0.820225           0.792135   \n",
       "21           0.810056           0.831461           0.792135   \n",
       "20           0.798883           0.808989           0.786517   \n",
       "19           0.815642           0.837079           0.769663   \n",
       "18           0.798883           0.808989           0.786517   \n",
       "59           0.798883           0.820225           0.803371   \n",
       "16           0.798883           0.825843           0.786517   \n",
       "14           0.798883           0.825843           0.786517   \n",
       "57           0.804469           0.831461           0.775281   \n",
       "12           0.798883           0.825843           0.786517   \n",
       "29           0.810056           0.820225           0.769663   \n",
       "54           0.793296           0.808989           0.814607   \n",
       "56           0.793296           0.808989           0.814607   \n",
       "23           0.804469           0.803371           0.792135   \n",
       "58           0.793296           0.808989           0.814607   \n",
       "47           0.787709           0.820225           0.792135   \n",
       "15           0.810056           0.814607           0.758427   \n",
       "43           0.787709           0.808989           0.820225   \n",
       "24           0.787709           0.820225           0.769663   \n",
       "28           0.782123           0.814607           0.786517   \n",
       "51           0.759777           0.820225           0.775281   \n",
       "26           0.787709           0.814607           0.780899   \n",
       "13           0.810056           0.803371           0.792135   \n",
       "7            0.798883           0.786517           0.758427   \n",
       "37           0.793296           0.814607           0.797753   \n",
       "45           0.810056           0.797753           0.780899   \n",
       "36           0.787709           0.814607           0.797753   \n",
       "38           0.787709           0.814607           0.797753   \n",
       "40           0.787709           0.814607           0.797753   \n",
       "39           0.798883           0.786517           0.792135   \n",
       "41           0.798883           0.792135           0.797753   \n",
       "9            0.798883           0.814607           0.758427   \n",
       "30           0.787709           0.786517           0.769663   \n",
       "35           0.787709           0.786517           0.769663   \n",
       "34           0.787709           0.786517           0.769663   \n",
       "33           0.787709           0.786517           0.769663   \n",
       "32           0.787709           0.786517           0.769663   \n",
       "31           0.787709           0.786517           0.769663   \n",
       "10           0.798883           0.814607           0.752809   \n",
       "8            0.798883           0.814607           0.752809   \n",
       "6            0.798883           0.814607           0.752809   \n",
       "11           0.787709           0.792135           0.758427   \n",
       "1            0.787709           0.786517           0.752809   \n",
       "5            0.787709           0.786517           0.752809   \n",
       "4            0.787709           0.786517           0.752809   \n",
       "3            0.787709           0.786517           0.752809   \n",
       "2            0.787709           0.786517           0.752809   \n",
       "0            0.787709           0.786517           0.752809   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "48           0.881356         0.837262        0.023968                1  \n",
       "50           0.870056         0.835017        0.019921                2  \n",
       "52           0.870056         0.835017        0.019921                2  \n",
       "49           0.841808         0.827160        0.022923                4  \n",
       "27           0.841808         0.824916        0.028382                5  \n",
       "53           0.847458         0.823793        0.020507                6  \n",
       "17           0.853107         0.821549        0.026518                7  \n",
       "55           0.830508         0.820426        0.014058                8  \n",
       "42           0.847458         0.818182        0.018555                9  \n",
       "25           0.858757         0.817059        0.032173               10  \n",
       "44           0.847458         0.817059        0.019879               10  \n",
       "22           0.841808         0.817059        0.021597               10  \n",
       "46           0.847458         0.817059        0.019879               10  \n",
       "21           0.830508         0.814815        0.014702               14  \n",
       "20           0.841808         0.814815        0.021688               14  \n",
       "19           0.836158         0.814815        0.024435               14  \n",
       "18           0.841808         0.814815        0.021688               14  \n",
       "59           0.847458         0.814815        0.017782               14  \n",
       "16           0.830508         0.813692        0.017660               19  \n",
       "14           0.830508         0.813692        0.017660               19  \n",
       "57           0.841808         0.813692        0.023081               19  \n",
       "12           0.830508         0.813692        0.017660               19  \n",
       "29           0.836158         0.811448        0.022474               23  \n",
       "54           0.847458         0.811448        0.019829               23  \n",
       "56           0.847458         0.809203        0.022242               25  \n",
       "23           0.830508         0.809203        0.012961               25  \n",
       "58           0.841808         0.808081        0.020345               27  \n",
       "47           0.813559         0.808081        0.015495               27  \n",
       "15           0.796610         0.803591        0.026221               29  \n",
       "43           0.836158         0.800224        0.030308               30  \n",
       "24           0.813559         0.797980        0.018128               31  \n",
       "28           0.819209         0.797980        0.015579               31  \n",
       "51           0.830508         0.794613        0.026740               33  \n",
       "26           0.807910         0.794613        0.013909               33  \n",
       "13           0.847458         0.793490        0.043458               35  \n",
       "7            0.824859         0.790123        0.021709               36  \n",
       "37           0.796610         0.790123        0.022093               36  \n",
       "45           0.807910         0.789001        0.022724               38  \n",
       "36           0.796610         0.789001        0.022045               38  \n",
       "38           0.796610         0.789001        0.022045               38  \n",
       "40           0.796610         0.789001        0.022045               38  \n",
       "39           0.796610         0.784512        0.018494               42  \n",
       "41           0.785311         0.784512        0.018636               42  \n",
       "9            0.796610         0.783389        0.025401               44  \n",
       "30           0.785311         0.782267        0.006568               45  \n",
       "35           0.785311         0.782267        0.006568               45  \n",
       "34           0.785311         0.782267        0.006568               45  \n",
       "33           0.785311         0.782267        0.006568               45  \n",
       "32           0.785311         0.782267        0.006568               45  \n",
       "31           0.785311         0.782267        0.006568               45  \n",
       "10           0.796610         0.782267        0.026576               45  \n",
       "8            0.796610         0.782267        0.026576               45  \n",
       "6            0.796610         0.782267        0.026576               45  \n",
       "11           0.785311         0.781145        0.011812               54  \n",
       "1            0.785311         0.778900        0.013169               55  \n",
       "5            0.785311         0.778900        0.013169               55  \n",
       "4            0.785311         0.778900        0.013169               55  \n",
       "3            0.785311         0.778900        0.013169               55  \n",
       "2            0.785311         0.778900        0.013169               55  \n",
       "0            0.785311         0.778900        0.013169               55  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = ModelGridSearch(RandomForestClassifier(), {'max_depth': [1, 2, 3, 4, 5],\n",
    "                                           'min_samples_leaf': [1, 2, 3],\n",
    "                                           'n_estimators': [100, 200, 300],\n",
    "                                           'random_state': [1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.322354</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.021143</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.860335</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.024660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.321505</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>0.021335</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.833895</td>\n",
       "      <td>0.023586</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.218635</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.017154</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.831650</td>\n",
       "      <td>0.022611</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.108422</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.217070</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.024339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.327921</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>0.022139</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.024339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.216203</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.014356</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.024339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.109898</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.024339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.324980</td>\n",
       "      <td>0.006054</td>\n",
       "      <td>0.021542</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.024779</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.214017</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.017601</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.025091</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.218814</td>\n",
       "      <td>0.013301</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>0.026598</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.324395</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>0.020781</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.320508</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.209517</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.015840</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.028439</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.107622</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.027693</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.107832</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.026008</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.109638</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.826038</td>\n",
       "      <td>0.025782</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.108552</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.824916</td>\n",
       "      <td>0.026299</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.315852</td>\n",
       "      <td>0.006929</td>\n",
       "      <td>0.020496</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.425208</td>\n",
       "      <td>0.055278</td>\n",
       "      <td>0.028731</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.253736</td>\n",
       "      <td>0.033087</td>\n",
       "      <td>0.015101</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.230568</td>\n",
       "      <td>0.017677</td>\n",
       "      <td>0.016804</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.318449</td>\n",
       "      <td>0.011309</td>\n",
       "      <td>0.021117</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.219576</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.108035</td>\n",
       "      <td>0.007058</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.107309</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.009231</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.815937</td>\n",
       "      <td>0.023085</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.152398</td>\n",
       "      <td>0.042893</td>\n",
       "      <td>0.016352</td>\n",
       "      <td>0.019408</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.024172</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.107613</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>0.006047</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.020702</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.102719</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.020702</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.102839</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.789001</td>\n",
       "      <td>0.020702</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.292630</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.020159</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294092</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.020640</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.304408</td>\n",
       "      <td>0.009843</td>\n",
       "      <td>0.018503</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.018887</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.198643</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.013361</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.019034</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.200246</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.015120</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.019034</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.203275</td>\n",
       "      <td>0.006853</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.019034</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.217456</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.310523</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.017521</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.201999</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.012587</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.301798</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.019439</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.203448</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.310487</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.020820</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.785634</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.099424</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.009063</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 3, 'n_est...</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102909</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.006053</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101582</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.007035</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "41       0.322354      0.000839         0.021143        0.000399   \n",
       "44       0.321505      0.000928         0.021335        0.000480   \n",
       "43       0.218635      0.003055         0.017154        0.003908   \n",
       "42       0.108422      0.000609         0.007773        0.000395   \n",
       "40       0.217070      0.001839         0.014762        0.000400   \n",
       "38       0.327921      0.005536         0.022139        0.000978   \n",
       "37       0.216203      0.000491         0.014356        0.000512   \n",
       "36       0.109898      0.000381         0.007780        0.000403   \n",
       "29       0.324980      0.006054         0.021542        0.000798   \n",
       "28       0.214017      0.002859         0.017601        0.004763   \n",
       "31       0.218814      0.013301         0.014362        0.000489   \n",
       "32       0.324395      0.006048         0.020781        0.000324   \n",
       "35       0.320508      0.006173         0.021142        0.000395   \n",
       "34       0.209517      0.003679         0.015840        0.002770   \n",
       "33       0.107622      0.001608         0.007775        0.000397   \n",
       "27       0.107832      0.000550         0.007990        0.000043   \n",
       "39       0.109638      0.000521         0.007974        0.000015   \n",
       "30       0.108552      0.003208         0.006792        0.002372   \n",
       "23       0.315852      0.006929         0.020496        0.000368   \n",
       "26       0.425208      0.055278         0.028731        0.008047   \n",
       "25       0.253736      0.033087         0.015101        0.005388   \n",
       "22       0.230568      0.017677         0.016804        0.002475   \n",
       "20       0.318449      0.011309         0.021117        0.000766   \n",
       "19       0.219576      0.009210         0.013632        0.002248   \n",
       "18       0.108035      0.007058         0.008276        0.001780   \n",
       "21       0.107309      0.007078         0.009231        0.001042   \n",
       "24       0.152398      0.042893         0.016352        0.019408   \n",
       "12       0.107613      0.005936         0.006047        0.002258   \n",
       "9        0.102719      0.001239         0.008010        0.000038   \n",
       "15       0.102839      0.003141         0.006472        0.004494   \n",
       "2        0.292630      0.005317         0.020159        0.000115   \n",
       "5        0.294092      0.004179         0.020640        0.000915   \n",
       "8        0.304408      0.009843         0.018503        0.003343   \n",
       "4        0.198643      0.003261         0.013361        0.000491   \n",
       "7        0.200246      0.005036         0.015120        0.004242   \n",
       "1        0.203275      0.006853         0.015800        0.003202   \n",
       "10       0.217456      0.007227         0.015436        0.003318   \n",
       "11       0.310523      0.009634         0.017521        0.003651   \n",
       "13       0.201999      0.002451         0.012587        0.001319   \n",
       "14       0.301798      0.004739         0.019439        0.001076   \n",
       "16       0.203448      0.003172         0.011609        0.001294   \n",
       "17       0.310487      0.005353         0.020820        0.001218   \n",
       "6        0.099424      0.003247         0.009063        0.001294   \n",
       "3        0.102909      0.003337         0.006053        0.004229   \n",
       "0        0.101582      0.003701         0.007035        0.003720   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf param_n_estimators  \\\n",
       "41               5                      2                300   \n",
       "44               5                      3                300   \n",
       "43               5                      3                200   \n",
       "42               5                      3                100   \n",
       "40               5                      2                200   \n",
       "38               5                      1                300   \n",
       "37               5                      1                200   \n",
       "36               5                      1                100   \n",
       "29               4                      1                300   \n",
       "28               4                      1                200   \n",
       "31               4                      2                200   \n",
       "32               4                      2                300   \n",
       "35               4                      3                300   \n",
       "34               4                      3                200   \n",
       "33               4                      3                100   \n",
       "27               4                      1                100   \n",
       "39               5                      2                100   \n",
       "30               4                      2                100   \n",
       "23               3                      2                300   \n",
       "26               3                      3                300   \n",
       "25               3                      3                200   \n",
       "22               3                      2                200   \n",
       "20               3                      1                300   \n",
       "19               3                      1                200   \n",
       "18               3                      1                100   \n",
       "21               3                      2                100   \n",
       "24               3                      3                100   \n",
       "12               2                      2                100   \n",
       "9                2                      1                100   \n",
       "15               2                      3                100   \n",
       "2                1                      1                300   \n",
       "5                1                      2                300   \n",
       "8                1                      3                300   \n",
       "4                1                      2                200   \n",
       "7                1                      3                200   \n",
       "1                1                      1                200   \n",
       "10               2                      1                200   \n",
       "11               2                      1                300   \n",
       "13               2                      2                200   \n",
       "14               2                      2                300   \n",
       "16               2                      3                200   \n",
       "17               2                      3                300   \n",
       "6                1                      3                100   \n",
       "3                1                      2                100   \n",
       "0                1                      1                100   \n",
       "\n",
       "   param_random_state                                             params  \\\n",
       "41                  1  {'max_depth': 5, 'min_samples_leaf': 2, 'n_est...   \n",
       "44                  1  {'max_depth': 5, 'min_samples_leaf': 3, 'n_est...   \n",
       "43                  1  {'max_depth': 5, 'min_samples_leaf': 3, 'n_est...   \n",
       "42                  1  {'max_depth': 5, 'min_samples_leaf': 3, 'n_est...   \n",
       "40                  1  {'max_depth': 5, 'min_samples_leaf': 2, 'n_est...   \n",
       "38                  1  {'max_depth': 5, 'min_samples_leaf': 1, 'n_est...   \n",
       "37                  1  {'max_depth': 5, 'min_samples_leaf': 1, 'n_est...   \n",
       "36                  1  {'max_depth': 5, 'min_samples_leaf': 1, 'n_est...   \n",
       "29                  1  {'max_depth': 4, 'min_samples_leaf': 1, 'n_est...   \n",
       "28                  1  {'max_depth': 4, 'min_samples_leaf': 1, 'n_est...   \n",
       "31                  1  {'max_depth': 4, 'min_samples_leaf': 2, 'n_est...   \n",
       "32                  1  {'max_depth': 4, 'min_samples_leaf': 2, 'n_est...   \n",
       "35                  1  {'max_depth': 4, 'min_samples_leaf': 3, 'n_est...   \n",
       "34                  1  {'max_depth': 4, 'min_samples_leaf': 3, 'n_est...   \n",
       "33                  1  {'max_depth': 4, 'min_samples_leaf': 3, 'n_est...   \n",
       "27                  1  {'max_depth': 4, 'min_samples_leaf': 1, 'n_est...   \n",
       "39                  1  {'max_depth': 5, 'min_samples_leaf': 2, 'n_est...   \n",
       "30                  1  {'max_depth': 4, 'min_samples_leaf': 2, 'n_est...   \n",
       "23                  1  {'max_depth': 3, 'min_samples_leaf': 2, 'n_est...   \n",
       "26                  1  {'max_depth': 3, 'min_samples_leaf': 3, 'n_est...   \n",
       "25                  1  {'max_depth': 3, 'min_samples_leaf': 3, 'n_est...   \n",
       "22                  1  {'max_depth': 3, 'min_samples_leaf': 2, 'n_est...   \n",
       "20                  1  {'max_depth': 3, 'min_samples_leaf': 1, 'n_est...   \n",
       "19                  1  {'max_depth': 3, 'min_samples_leaf': 1, 'n_est...   \n",
       "18                  1  {'max_depth': 3, 'min_samples_leaf': 1, 'n_est...   \n",
       "21                  1  {'max_depth': 3, 'min_samples_leaf': 2, 'n_est...   \n",
       "24                  1  {'max_depth': 3, 'min_samples_leaf': 3, 'n_est...   \n",
       "12                  1  {'max_depth': 2, 'min_samples_leaf': 2, 'n_est...   \n",
       "9                   1  {'max_depth': 2, 'min_samples_leaf': 1, 'n_est...   \n",
       "15                  1  {'max_depth': 2, 'min_samples_leaf': 3, 'n_est...   \n",
       "2                   1  {'max_depth': 1, 'min_samples_leaf': 1, 'n_est...   \n",
       "5                   1  {'max_depth': 1, 'min_samples_leaf': 2, 'n_est...   \n",
       "8                   1  {'max_depth': 1, 'min_samples_leaf': 3, 'n_est...   \n",
       "4                   1  {'max_depth': 1, 'min_samples_leaf': 2, 'n_est...   \n",
       "7                   1  {'max_depth': 1, 'min_samples_leaf': 3, 'n_est...   \n",
       "1                   1  {'max_depth': 1, 'min_samples_leaf': 1, 'n_est...   \n",
       "10                  1  {'max_depth': 2, 'min_samples_leaf': 1, 'n_est...   \n",
       "11                  1  {'max_depth': 2, 'min_samples_leaf': 1, 'n_est...   \n",
       "13                  1  {'max_depth': 2, 'min_samples_leaf': 2, 'n_est...   \n",
       "14                  1  {'max_depth': 2, 'min_samples_leaf': 2, 'n_est...   \n",
       "16                  1  {'max_depth': 2, 'min_samples_leaf': 3, 'n_est...   \n",
       "17                  1  {'max_depth': 2, 'min_samples_leaf': 3, 'n_est...   \n",
       "6                   1  {'max_depth': 1, 'min_samples_leaf': 3, 'n_est...   \n",
       "3                   1  {'max_depth': 1, 'min_samples_leaf': 2, 'n_est...   \n",
       "0                   1  {'max_depth': 1, 'min_samples_leaf': 1, 'n_est...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "41           0.860335           0.826816           0.825843   \n",
       "44           0.854749           0.826816           0.825843   \n",
       "43           0.854749           0.821229           0.825843   \n",
       "42           0.854749           0.826816           0.825843   \n",
       "40           0.854749           0.821229           0.825843   \n",
       "38           0.854749           0.821229           0.825843   \n",
       "37           0.854749           0.821229           0.825843   \n",
       "36           0.854749           0.821229           0.825843   \n",
       "29           0.849162           0.821229           0.825843   \n",
       "28           0.849162           0.821229           0.820225   \n",
       "31           0.849162           0.826816           0.820225   \n",
       "32           0.843575           0.826816           0.825843   \n",
       "35           0.843575           0.826816           0.825843   \n",
       "34           0.849162           0.826816           0.820225   \n",
       "33           0.843575           0.826816           0.820225   \n",
       "27           0.843575           0.821229           0.820225   \n",
       "39           0.849162           0.821229           0.825843   \n",
       "30           0.843575           0.821229           0.820225   \n",
       "23           0.843575           0.826816           0.814607   \n",
       "26           0.843575           0.826816           0.814607   \n",
       "25           0.843575           0.826816           0.814607   \n",
       "22           0.843575           0.826816           0.814607   \n",
       "20           0.843575           0.826816           0.814607   \n",
       "19           0.843575           0.826816           0.814607   \n",
       "18           0.843575           0.826816           0.814607   \n",
       "21           0.843575           0.826816           0.808989   \n",
       "24           0.843575           0.826816           0.797753   \n",
       "12           0.798883           0.815642           0.792135   \n",
       "9            0.798883           0.815642           0.792135   \n",
       "15           0.798883           0.815642           0.792135   \n",
       "2            0.804469           0.804469           0.786517   \n",
       "5            0.804469           0.804469           0.786517   \n",
       "8            0.804469           0.804469           0.786517   \n",
       "4            0.804469           0.804469           0.780899   \n",
       "7            0.804469           0.804469           0.780899   \n",
       "1            0.804469           0.804469           0.780899   \n",
       "10           0.798883           0.804469           0.786517   \n",
       "11           0.798883           0.804469           0.786517   \n",
       "13           0.798883           0.804469           0.786517   \n",
       "14           0.798883           0.804469           0.786517   \n",
       "16           0.798883           0.804469           0.786517   \n",
       "17           0.798883           0.804469           0.786517   \n",
       "6            0.754190           0.804469           0.780899   \n",
       "3            0.754190           0.804469           0.780899   \n",
       "0            0.754190           0.804469           0.780899   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "41           0.797753           0.864407         0.835017        0.024660   \n",
       "44           0.797753           0.864407         0.833895        0.023586   \n",
       "43           0.797753           0.858757         0.831650        0.022611   \n",
       "42           0.786517           0.858757         0.830527        0.025890   \n",
       "40           0.792135           0.858757         0.830527        0.024339   \n",
       "38           0.792135           0.858757         0.830527        0.024339   \n",
       "37           0.792135           0.858757         0.830527        0.024339   \n",
       "36           0.792135           0.858757         0.830527        0.024339   \n",
       "29           0.792135           0.864407         0.830527        0.024779   \n",
       "28           0.792135           0.864407         0.829405        0.025091   \n",
       "31           0.786517           0.864407         0.829405        0.026598   \n",
       "32           0.780899           0.864407         0.828283        0.027502   \n",
       "35           0.780899           0.864407         0.828283        0.027502   \n",
       "34           0.780899           0.864407         0.828283        0.028439   \n",
       "33           0.780899           0.864407         0.827160        0.027693   \n",
       "27           0.786517           0.864407         0.827160        0.026008   \n",
       "39           0.780899           0.853107         0.826038        0.025782   \n",
       "30           0.780899           0.858757         0.824916        0.026299   \n",
       "23           0.775281           0.824859         0.817059        0.022855   \n",
       "26           0.775281           0.824859         0.817059        0.022855   \n",
       "25           0.775281           0.824859         0.817059        0.022855   \n",
       "22           0.775281           0.824859         0.817059        0.022855   \n",
       "20           0.775281           0.824859         0.817059        0.022855   \n",
       "19           0.775281           0.824859         0.817059        0.022855   \n",
       "18           0.775281           0.824859         0.817059        0.022855   \n",
       "21           0.775281           0.824859         0.815937        0.023085   \n",
       "24           0.775281           0.824859         0.813692        0.024172   \n",
       "12           0.752809           0.785311         0.789001        0.020702   \n",
       "9            0.752809           0.785311         0.789001        0.020702   \n",
       "15           0.752809           0.785311         0.789001        0.020702   \n",
       "2            0.752809           0.785311         0.786756        0.018887   \n",
       "5            0.752809           0.785311         0.786756        0.018887   \n",
       "8            0.752809           0.785311         0.786756        0.018887   \n",
       "4            0.752809           0.785311         0.785634        0.019034   \n",
       "7            0.752809           0.785311         0.785634        0.019034   \n",
       "1            0.752809           0.785311         0.785634        0.019034   \n",
       "10           0.752809           0.785311         0.785634        0.017943   \n",
       "11           0.752809           0.785311         0.785634        0.017943   \n",
       "13           0.752809           0.785311         0.785634        0.017943   \n",
       "14           0.752809           0.785311         0.785634        0.017943   \n",
       "16           0.752809           0.785311         0.785634        0.017943   \n",
       "17           0.752809           0.785311         0.785634        0.017943   \n",
       "6            0.752809           0.785311         0.775533        0.019688   \n",
       "3            0.752809           0.785311         0.775533        0.019688   \n",
       "0            0.752809           0.785311         0.775533        0.019688   \n",
       "\n",
       "    rank_test_score  \n",
       "41                1  \n",
       "44                2  \n",
       "43                3  \n",
       "42                4  \n",
       "40                4  \n",
       "38                4  \n",
       "37                4  \n",
       "36                4  \n",
       "29                4  \n",
       "28               10  \n",
       "31               10  \n",
       "32               12  \n",
       "35               12  \n",
       "34               12  \n",
       "33               15  \n",
       "27               15  \n",
       "39               17  \n",
       "30               18  \n",
       "23               19  \n",
       "26               19  \n",
       "25               19  \n",
       "22               19  \n",
       "20               19  \n",
       "19               19  \n",
       "18               19  \n",
       "21               26  \n",
       "24               27  \n",
       "12               28  \n",
       "9                28  \n",
       "15               28  \n",
       "2                31  \n",
       "5                31  \n",
       "8                31  \n",
       "4                34  \n",
       "7                34  \n",
       "1                34  \n",
       "10               34  \n",
       "11               34  \n",
       "13               34  \n",
       "14               34  \n",
       "16               34  \n",
       "17               34  \n",
       "6                43  \n",
       "3                43  \n",
       "0                43  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_results = ModelGridSearch(SVC(), {'C': [1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4],\n",
    "                        'gamma': ['scale', 'auto'], \n",
    "                        #'kernel': ['rbf', 'poly', 'linear', 'sigmoid'],\n",
    "                        'random_state': [1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.070535</td>\n",
       "      <td>0.018735</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>4.025991e-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>scale</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1000.0, 'gamma': 'scale', 'random_state'...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.820426</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.443546</td>\n",
       "      <td>0.077616</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>6.843901e-07</td>\n",
       "      <td>10000</td>\n",
       "      <td>scale</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 10000.0, 'gamma': 'scale', 'random_state...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.815937</td>\n",
       "      <td>0.025575</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.024978</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>1.964491e-03</td>\n",
       "      <td>100</td>\n",
       "      <td>scale</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 100.0, 'gamma': 'scale', 'random_state': 1}</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.805836</td>\n",
       "      <td>0.030876</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.019341</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>6.810597e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 10.0, 'gamma': 'scale', 'random_state': 1}</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.758698</td>\n",
       "      <td>0.050970</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.026130</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>4.889476e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 10.0, 'gamma': 'auto', 'random_state': 1}</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>0.749719</td>\n",
       "      <td>0.027933</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.022149</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>4.892430e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'auto', 'random_state': 1}</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>0.739618</td>\n",
       "      <td>0.023306</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.041004</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>4.264961e-07</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 100.0, 'gamma': 'auto', 'random_state': 1}</td>\n",
       "      <td>0.687151</td>\n",
       "      <td>0.715084</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.730337</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.025652</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.100537</td>\n",
       "      <td>0.032013</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>3.957221e-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1000.0, 'gamma': 'auto', 'random_state': 1}</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.731844</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.713483</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.725028</td>\n",
       "      <td>0.020069</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.302889</td>\n",
       "      <td>0.057763</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>2.680302e-03</td>\n",
       "      <td>10000</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 10000.0, 'gamma': 'auto', 'random_state'...</td>\n",
       "      <td>0.720670</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.027980</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019873</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>1.459147e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'random_state': 1}</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.720670</td>\n",
       "      <td>0.691011</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.689266</td>\n",
       "      <td>0.674523</td>\n",
       "      <td>0.045850</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019548</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>4.888740e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'scale', 'random_state': 1}</td>\n",
       "      <td>0.581006</td>\n",
       "      <td>0.715084</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.665544</td>\n",
       "      <td>0.045539</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021947</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>7.627010e-06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.1, 'gamma': 'auto', 'random_state': 1}</td>\n",
       "      <td>0.631285</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.623596</td>\n",
       "      <td>0.623596</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.621773</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021956</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>1.745081e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 'scale', 'random_state': 1}</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022720</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>1.929750e-03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>auto</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.01, 'gamma': 'auto', 'random_state': 1}</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "10       0.070535      0.018735         0.003184    4.025991e-04    1000   \n",
       "12       0.443546      0.077616         0.002991    6.843901e-07   10000   \n",
       "8        0.024978      0.002532         0.004204    1.964491e-03     100   \n",
       "6        0.019341      0.000493         0.003989    6.810597e-07      10   \n",
       "7        0.026130      0.001163         0.004388    4.889476e-04      10   \n",
       "5        0.022149      0.000753         0.004387    4.892430e-04       1   \n",
       "9        0.041004      0.004849         0.003989    4.264961e-07     100   \n",
       "11       0.100537      0.032013         0.003787    3.957221e-04    1000   \n",
       "13       0.302889      0.057763         0.004809    2.680302e-03   10000   \n",
       "4        0.019873      0.001950         0.003782    1.459147e-03       1   \n",
       "2        0.019548      0.000487         0.004588    4.888740e-04     0.1   \n",
       "3        0.021947      0.000008         0.004981    7.627010e-06     0.1   \n",
       "0        0.021956      0.001083         0.004981    1.745081e-05    0.01   \n",
       "1        0.022720      0.002383         0.003791    1.929750e-03    0.01   \n",
       "\n",
       "   param_gamma param_random_state  \\\n",
       "10       scale                  1   \n",
       "12       scale                  1   \n",
       "8        scale                  1   \n",
       "6        scale                  1   \n",
       "7         auto                  1   \n",
       "5         auto                  1   \n",
       "9         auto                  1   \n",
       "11        auto                  1   \n",
       "13        auto                  1   \n",
       "4        scale                  1   \n",
       "2        scale                  1   \n",
       "3         auto                  1   \n",
       "0        scale                  1   \n",
       "1         auto                  1   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "10  {'C': 1000.0, 'gamma': 'scale', 'random_state'...           0.837989   \n",
       "12  {'C': 10000.0, 'gamma': 'scale', 'random_state...           0.843575   \n",
       "8   {'C': 100.0, 'gamma': 'scale', 'random_state': 1}           0.815642   \n",
       "6    {'C': 10.0, 'gamma': 'scale', 'random_state': 1}           0.670391   \n",
       "7     {'C': 10.0, 'gamma': 'auto', 'random_state': 1}           0.698324   \n",
       "5      {'C': 1.0, 'gamma': 'auto', 'random_state': 1}           0.698324   \n",
       "9    {'C': 100.0, 'gamma': 'auto', 'random_state': 1}           0.687151   \n",
       "11  {'C': 1000.0, 'gamma': 'auto', 'random_state': 1}           0.698324   \n",
       "13  {'C': 10000.0, 'gamma': 'auto', 'random_state'...           0.720670   \n",
       "4     {'C': 1.0, 'gamma': 'scale', 'random_state': 1}           0.586592   \n",
       "2     {'C': 0.1, 'gamma': 'scale', 'random_state': 1}           0.581006   \n",
       "3      {'C': 0.1, 'gamma': 'auto', 'random_state': 1}           0.631285   \n",
       "0    {'C': 0.01, 'gamma': 'scale', 'random_state': 1}           0.614525   \n",
       "1     {'C': 0.01, 'gamma': 'auto', 'random_state': 1}           0.614525   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "10           0.815642           0.803371           0.786517   \n",
       "12           0.804469           0.803371           0.780899   \n",
       "8            0.810056           0.792135           0.758427   \n",
       "6            0.759777           0.752809           0.786517   \n",
       "7            0.743017           0.775281           0.764045   \n",
       "5            0.737430           0.741573           0.752809   \n",
       "9            0.715084           0.764045           0.730337   \n",
       "11           0.731844           0.758427           0.713483   \n",
       "13           0.670391           0.758427           0.719101   \n",
       "4            0.720670           0.691011           0.685393   \n",
       "2            0.715084           0.662921           0.685393   \n",
       "3            0.614525           0.623596           0.623596   \n",
       "0            0.614525           0.617978           0.617978   \n",
       "1            0.614525           0.617978           0.617978   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "10           0.858757         0.820426        0.025422                1  \n",
       "12           0.847458         0.815937        0.025575                2  \n",
       "8            0.853107         0.805836        0.030876                3  \n",
       "6            0.824859         0.758698        0.050970                4  \n",
       "7            0.768362         0.749719        0.027933                5  \n",
       "5            0.768362         0.739618        0.023306                6  \n",
       "9            0.740113         0.727273        0.025652                7  \n",
       "11           0.723164         0.725028        0.020069                8  \n",
       "13           0.717514         0.717172        0.027980                9  \n",
       "4            0.689266         0.674523        0.045850               10  \n",
       "2            0.683616         0.665544        0.045539               11  \n",
       "3            0.615819         0.621773        0.006091               12  \n",
       "0            0.615819         0.616162        0.001555               13  \n",
       "1            0.615819         0.616162        0.001555               13  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_results = ModelGridSearch(MLPClassifier(), {'max_iter': [100, 200, 500, 1000],\n",
    "                                                'alpha': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "                                                'solver': ['sgd', 'adam'],\n",
    "                                                'random_state': [1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.994419</td>\n",
       "      <td>0.228448</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.306003e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 500, 'random_state...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.028910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.931529</td>\n",
       "      <td>0.175551</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.884609e-04</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 1e-05, 'max_iter': 500, 'random_stat...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.895583</td>\n",
       "      <td>0.154782</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.884414e-04</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 1e-05, 'max_iter': 1000, 'random_sta...</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.002732</td>\n",
       "      <td>0.228903</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>7.982256e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 1000, 'random_stat...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.817059</td>\n",
       "      <td>0.028910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.834281</td>\n",
       "      <td>0.198923</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.989935e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.001, 'max_iter': 1000, 'random_sta...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.815937</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.822914</td>\n",
       "      <td>0.212455</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.990421e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.001, 'max_iter': 500, 'random_stat...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.815937</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.899010</td>\n",
       "      <td>0.149401</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>4.885000e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.0001, 'max_iter': 500, 'random_sta...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.028196</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.727866</td>\n",
       "      <td>0.121080</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>4.881884e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.001, 'max_iter': 200, 'random_stat...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.028544</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.828145</td>\n",
       "      <td>0.136756</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>6.986523e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 200, 'random_state'...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.024619</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.939671</td>\n",
       "      <td>0.122190</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>9.795862e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.0001, 'max_iter': 1000, 'random_st...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.813692</td>\n",
       "      <td>0.028196</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.756639</td>\n",
       "      <td>0.085046</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.882274e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.0001, 'max_iter': 200, 'random_sta...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.812570</td>\n",
       "      <td>0.025755</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.792106</td>\n",
       "      <td>0.102077</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>2.138954e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 200, 'random_state...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.812570</td>\n",
       "      <td>0.027406</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.834395</td>\n",
       "      <td>0.144574</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>7.979639e-04</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 1e-05, 'max_iter': 200, 'random_stat...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.858757</td>\n",
       "      <td>0.811448</td>\n",
       "      <td>0.027513</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.216938</td>\n",
       "      <td>0.433052</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>1.092885e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 1000, 'random_state...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.810325</td>\n",
       "      <td>0.024301</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.058272</td>\n",
       "      <td>0.332386</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.886752e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 500, 'random_state'...</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.810325</td>\n",
       "      <td>0.024301</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.382018</td>\n",
       "      <td>0.027330</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.889281e-04</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 1e-05, 'max_iter': 100, 'random_stat...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.805836</td>\n",
       "      <td>0.027501</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.474745</td>\n",
       "      <td>0.042785</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>4.829074e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 100, 'random_state...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.434349</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>4.883830e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 100, 'random_state'...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.408864</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>3.998043e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.001, 'max_iter': 100, 'random_stat...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.804714</td>\n",
       "      <td>0.028320</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.406335</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>4.896895e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>{'alpha': 0.0001, 'max_iter': 100, 'random_sta...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.803591</td>\n",
       "      <td>0.027748</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.543835</td>\n",
       "      <td>0.155908</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>3.991605e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.001, 'max_iter': 1000, 'random_sta...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.592434</td>\n",
       "      <td>0.178369</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>3.989506e-07</td>\n",
       "      <td>0.001</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.001, 'max_iter': 500, 'random_stat...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.542088</td>\n",
       "      <td>0.163975</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.885981e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.001, 'max_iter': 200, 'random_stat...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.573928</td>\n",
       "      <td>0.149130</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>6.306774e-04</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 1e-05, 'max_iter': 500, 'random_stat...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.539197</td>\n",
       "      <td>0.158373</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.885582e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.0001, 'max_iter': 1000, 'random_st...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.536058</td>\n",
       "      <td>0.153021</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>5.560829e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.0001, 'max_iter': 500, 'random_sta...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.565771</td>\n",
       "      <td>0.187882</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>7.008046e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.0001, 'max_iter': 200, 'random_sta...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478706</td>\n",
       "      <td>0.134038</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.988743e-04</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 1e-05, 'max_iter': 200, 'random_stat...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.482375</td>\n",
       "      <td>0.138409</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.884999e-04</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 1e-05, 'max_iter': 1000, 'random_sta...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.542110</td>\n",
       "      <td>0.177038</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.990174e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 200, 'random_state...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.792368</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.550096</td>\n",
       "      <td>0.171898</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>3.987552e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 500, 'random_state...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.792368</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.219982</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>3.983503e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 1000, 'random_stat...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.792368</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.583859</td>\n",
       "      <td>0.195723</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.885971e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 1000, 'random_state...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.542620</td>\n",
       "      <td>0.168173</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>4.884219e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 500, 'random_state'...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.554143</td>\n",
       "      <td>0.184926</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>3.540817e-06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 200, 'random_state'...</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.357393</td>\n",
       "      <td>0.027277</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>7.463150e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.0001, 'max_iter': 100, 'random_sta...</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.020816</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.371648</td>\n",
       "      <td>0.032063</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>6.306761e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.001, 'max_iter': 100, 'random_stat...</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.020816</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.387172</td>\n",
       "      <td>0.038182</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>7.459899e-04</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 1e-05, 'max_iter': 100, 'random_stat...</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.775533</td>\n",
       "      <td>0.020816</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.376149</td>\n",
       "      <td>0.022193</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>3.990650e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.01, 'max_iter': 100, 'random_state...</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.774411</td>\n",
       "      <td>0.020340</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.379766</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>9.781383e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>sgd</td>\n",
       "      <td>{'alpha': 0.1, 'max_iter': 100, 'random_state'...</td>\n",
       "      <td>0.731844</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.790960</td>\n",
       "      <td>0.773288</td>\n",
       "      <td>0.022399</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "29       0.994419      0.228448         0.001995    6.306003e-04        0.01   \n",
       "5        0.931529      0.175551         0.001396    4.884609e-04       1e-05   \n",
       "7        0.895583      0.154782         0.001596    4.884414e-04       1e-05   \n",
       "31       1.002732      0.228903         0.001596    7.982256e-04        0.01   \n",
       "23       0.834281      0.198923         0.001197    3.989935e-04       0.001   \n",
       "21       0.822914      0.212455         0.001795    3.990421e-04       0.001   \n",
       "13       0.899010      0.149401         0.001397    4.885000e-04      0.0001   \n",
       "19       0.727866      0.121080         0.002394    4.881884e-04       0.001   \n",
       "35       0.828145      0.136756         0.001844    6.986523e-04         0.1   \n",
       "15       0.939671      0.122190         0.001806    9.795862e-04      0.0001   \n",
       "11       0.756639      0.085046         0.001596    4.882274e-04      0.0001   \n",
       "27       0.792106      0.102077         0.002005    2.138954e-05        0.01   \n",
       "3        0.834395      0.144574         0.001396    7.979639e-04       1e-05   \n",
       "39       1.216938      0.433052         0.001995    1.092885e-03         0.1   \n",
       "37       1.058272      0.332386         0.001596    4.886752e-04         0.1   \n",
       "1        0.382018      0.027330         0.001596    4.889281e-04       1e-05   \n",
       "25       0.474745      0.042785         0.002401    4.829074e-04        0.01   \n",
       "33       0.434349      0.015907         0.002393    4.883830e-04         0.1   \n",
       "17       0.408864      0.018563         0.001794    3.998043e-04       0.001   \n",
       "9        0.406335      0.008555         0.001595    4.896895e-04      0.0001   \n",
       "22       0.543835      0.155908         0.001796    3.991605e-04       0.001   \n",
       "20       0.592434      0.178369         0.001995    3.989506e-07       0.001   \n",
       "18       0.542088      0.163975         0.001596    4.885981e-04       0.001   \n",
       "4        0.573928      0.149130         0.001994    6.306774e-04       1e-05   \n",
       "14       0.539197      0.158373         0.001596    4.885582e-04      0.0001   \n",
       "12       0.536058      0.153021         0.001994    5.560829e-07      0.0001   \n",
       "10       0.565771      0.187882         0.001995    7.008046e-07      0.0001   \n",
       "2        0.478706      0.134038         0.001795    3.988743e-04       1e-05   \n",
       "6        0.482375      0.138409         0.001396    4.884999e-04       1e-05   \n",
       "26       0.542110      0.177038         0.001795    3.990174e-04        0.01   \n",
       "28       0.550096      0.171898         0.001796    3.987552e-04        0.01   \n",
       "30       0.591837      0.219982         0.001796    3.983503e-04        0.01   \n",
       "38       0.583859      0.195723         0.001596    4.885971e-04         0.1   \n",
       "36       0.542620      0.168173         0.002394    4.884219e-04         0.1   \n",
       "34       0.554143      0.184926         0.001993    3.540817e-06         0.1   \n",
       "8        0.357393      0.027277         0.001795    7.463150e-04      0.0001   \n",
       "16       0.371648      0.032063         0.001994    6.306761e-04       0.001   \n",
       "0        0.387172      0.038182         0.001796    7.459899e-04       1e-05   \n",
       "24       0.376149      0.022193         0.001795    3.990650e-04        0.01   \n",
       "32       0.379766      0.023600         0.001621    9.781383e-04         0.1   \n",
       "\n",
       "   param_max_iter param_random_state param_solver  \\\n",
       "29            500                  1         adam   \n",
       "5             500                  1         adam   \n",
       "7            1000                  1         adam   \n",
       "31           1000                  1         adam   \n",
       "23           1000                  1         adam   \n",
       "21            500                  1         adam   \n",
       "13            500                  1         adam   \n",
       "19            200                  1         adam   \n",
       "35            200                  1         adam   \n",
       "15           1000                  1         adam   \n",
       "11            200                  1         adam   \n",
       "27            200                  1         adam   \n",
       "3             200                  1         adam   \n",
       "39           1000                  1         adam   \n",
       "37            500                  1         adam   \n",
       "1             100                  1         adam   \n",
       "25            100                  1         adam   \n",
       "33            100                  1         adam   \n",
       "17            100                  1         adam   \n",
       "9             100                  1         adam   \n",
       "22           1000                  1          sgd   \n",
       "20            500                  1          sgd   \n",
       "18            200                  1          sgd   \n",
       "4             500                  1          sgd   \n",
       "14           1000                  1          sgd   \n",
       "12            500                  1          sgd   \n",
       "10            200                  1          sgd   \n",
       "2             200                  1          sgd   \n",
       "6            1000                  1          sgd   \n",
       "26            200                  1          sgd   \n",
       "28            500                  1          sgd   \n",
       "30           1000                  1          sgd   \n",
       "38           1000                  1          sgd   \n",
       "36            500                  1          sgd   \n",
       "34            200                  1          sgd   \n",
       "8             100                  1          sgd   \n",
       "16            100                  1          sgd   \n",
       "0             100                  1          sgd   \n",
       "24            100                  1          sgd   \n",
       "32            100                  1          sgd   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "29  {'alpha': 0.01, 'max_iter': 500, 'random_state...           0.782123   \n",
       "5   {'alpha': 1e-05, 'max_iter': 500, 'random_stat...           0.821229   \n",
       "7   {'alpha': 1e-05, 'max_iter': 1000, 'random_sta...           0.821229   \n",
       "31  {'alpha': 0.01, 'max_iter': 1000, 'random_stat...           0.782123   \n",
       "23  {'alpha': 0.001, 'max_iter': 1000, 'random_sta...           0.793296   \n",
       "21  {'alpha': 0.001, 'max_iter': 500, 'random_stat...           0.793296   \n",
       "13  {'alpha': 0.0001, 'max_iter': 500, 'random_sta...           0.787709   \n",
       "19  {'alpha': 0.001, 'max_iter': 200, 'random_stat...           0.793296   \n",
       "35  {'alpha': 0.1, 'max_iter': 200, 'random_state'...           0.793296   \n",
       "15  {'alpha': 0.0001, 'max_iter': 1000, 'random_st...           0.787709   \n",
       "11  {'alpha': 0.0001, 'max_iter': 200, 'random_sta...           0.787709   \n",
       "27  {'alpha': 0.01, 'max_iter': 200, 'random_state...           0.782123   \n",
       "3   {'alpha': 1e-05, 'max_iter': 200, 'random_stat...           0.793296   \n",
       "39  {'alpha': 0.1, 'max_iter': 1000, 'random_state...           0.793296   \n",
       "37  {'alpha': 0.1, 'max_iter': 500, 'random_state'...           0.793296   \n",
       "1   {'alpha': 1e-05, 'max_iter': 100, 'random_stat...           0.787709   \n",
       "25  {'alpha': 0.01, 'max_iter': 100, 'random_state...           0.782123   \n",
       "33  {'alpha': 0.1, 'max_iter': 100, 'random_state'...           0.782123   \n",
       "17  {'alpha': 0.001, 'max_iter': 100, 'random_stat...           0.782123   \n",
       "9   {'alpha': 0.0001, 'max_iter': 100, 'random_sta...           0.782123   \n",
       "22  {'alpha': 0.001, 'max_iter': 1000, 'random_sta...           0.787709   \n",
       "20  {'alpha': 0.001, 'max_iter': 500, 'random_stat...           0.787709   \n",
       "18  {'alpha': 0.001, 'max_iter': 200, 'random_stat...           0.787709   \n",
       "4   {'alpha': 1e-05, 'max_iter': 500, 'random_stat...           0.787709   \n",
       "14  {'alpha': 0.0001, 'max_iter': 1000, 'random_st...           0.787709   \n",
       "12  {'alpha': 0.0001, 'max_iter': 500, 'random_sta...           0.787709   \n",
       "10  {'alpha': 0.0001, 'max_iter': 200, 'random_sta...           0.787709   \n",
       "2   {'alpha': 1e-05, 'max_iter': 200, 'random_stat...           0.787709   \n",
       "6   {'alpha': 1e-05, 'max_iter': 1000, 'random_sta...           0.787709   \n",
       "26  {'alpha': 0.01, 'max_iter': 200, 'random_state...           0.787709   \n",
       "28  {'alpha': 0.01, 'max_iter': 500, 'random_state...           0.787709   \n",
       "30  {'alpha': 0.01, 'max_iter': 1000, 'random_stat...           0.787709   \n",
       "38  {'alpha': 0.1, 'max_iter': 1000, 'random_state...           0.787709   \n",
       "36  {'alpha': 0.1, 'max_iter': 500, 'random_state'...           0.787709   \n",
       "34  {'alpha': 0.1, 'max_iter': 200, 'random_state'...           0.787709   \n",
       "8   {'alpha': 0.0001, 'max_iter': 100, 'random_sta...           0.737430   \n",
       "16  {'alpha': 0.001, 'max_iter': 100, 'random_stat...           0.737430   \n",
       "0   {'alpha': 1e-05, 'max_iter': 100, 'random_stat...           0.737430   \n",
       "24  {'alpha': 0.01, 'max_iter': 100, 'random_state...           0.737430   \n",
       "32  {'alpha': 0.1, 'max_iter': 100, 'random_state'...           0.731844   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "29           0.826816           0.820225           0.792135   \n",
       "5            0.821229           0.792135           0.786517   \n",
       "7            0.821229           0.792135           0.786517   \n",
       "31           0.826816           0.820225           0.792135   \n",
       "23           0.826816           0.808989           0.786517   \n",
       "21           0.826816           0.808989           0.786517   \n",
       "13           0.815642           0.814607           0.786517   \n",
       "19           0.826816           0.792135           0.792135   \n",
       "35           0.832402           0.797753           0.792135   \n",
       "15           0.815642           0.814607           0.786517   \n",
       "11           0.821229           0.803371           0.792135   \n",
       "27           0.826816           0.803371           0.792135   \n",
       "3            0.826816           0.786517           0.792135   \n",
       "39           0.821229           0.797753           0.786517   \n",
       "37           0.821229           0.797753           0.786517   \n",
       "1            0.821229           0.786517           0.780899   \n",
       "25           0.821229           0.786517           0.780899   \n",
       "33           0.821229           0.786517           0.780899   \n",
       "17           0.821229           0.786517           0.780899   \n",
       "9            0.815642           0.786517           0.780899   \n",
       "22           0.810056           0.792135           0.786517   \n",
       "20           0.810056           0.792135           0.786517   \n",
       "18           0.810056           0.792135           0.786517   \n",
       "4            0.810056           0.792135           0.786517   \n",
       "14           0.810056           0.792135           0.786517   \n",
       "12           0.810056           0.792135           0.786517   \n",
       "10           0.810056           0.792135           0.786517   \n",
       "2            0.810056           0.792135           0.786517   \n",
       "6            0.810056           0.792135           0.786517   \n",
       "26           0.810056           0.792135           0.780899   \n",
       "28           0.810056           0.792135           0.780899   \n",
       "30           0.810056           0.792135           0.780899   \n",
       "38           0.810056           0.792135           0.780899   \n",
       "36           0.810056           0.792135           0.780899   \n",
       "34           0.810056           0.792135           0.780899   \n",
       "8            0.793296           0.769663           0.786517   \n",
       "16           0.793296           0.769663           0.786517   \n",
       "0            0.793296           0.769663           0.786517   \n",
       "24           0.793296           0.769663           0.780899   \n",
       "32           0.793296           0.769663           0.780899   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "29           0.864407         0.817059        0.028910                1  \n",
       "5            0.864407         0.817059        0.027619                1  \n",
       "7            0.864407         0.817059        0.027619                1  \n",
       "31           0.864407         0.817059        0.028910                1  \n",
       "23           0.864407         0.815937        0.027857                5  \n",
       "21           0.864407         0.815937        0.027857                5  \n",
       "13           0.864407         0.813692        0.028196                7  \n",
       "19           0.864407         0.813692        0.028544                7  \n",
       "35           0.853107         0.813692        0.024619                7  \n",
       "15           0.864407         0.813692        0.028196                7  \n",
       "11           0.858757         0.812570        0.025755               11  \n",
       "27           0.858757         0.812570        0.027406               11  \n",
       "3            0.858757         0.811448        0.027513               13  \n",
       "39           0.853107         0.810325        0.024301               14  \n",
       "37           0.853107         0.810325        0.024301               14  \n",
       "1            0.853107         0.805836        0.027501               16  \n",
       "25           0.853107         0.804714        0.028320               17  \n",
       "33           0.853107         0.804714        0.028320               17  \n",
       "17           0.853107         0.804714        0.028320               17  \n",
       "9            0.853107         0.803591        0.027748               20  \n",
       "22           0.796610         0.794613        0.008521               21  \n",
       "20           0.796610         0.794613        0.008521               21  \n",
       "18           0.796610         0.794613        0.008521               21  \n",
       "4            0.796610         0.794613        0.008521               21  \n",
       "14           0.796610         0.794613        0.008521               21  \n",
       "12           0.796610         0.794613        0.008521               21  \n",
       "10           0.796610         0.794613        0.008521               21  \n",
       "2            0.796610         0.794613        0.008521               21  \n",
       "6            0.796610         0.794613        0.008521               21  \n",
       "26           0.790960         0.792368        0.009690               30  \n",
       "28           0.790960         0.792368        0.009690               30  \n",
       "30           0.790960         0.792368        0.009690               30  \n",
       "38           0.779661         0.790123        0.010979               33  \n",
       "36           0.779661         0.790123        0.010979               33  \n",
       "34           0.779661         0.790123        0.010979               33  \n",
       "8            0.790960         0.775533        0.020816               36  \n",
       "16           0.790960         0.775533        0.020816               36  \n",
       "0            0.790960         0.775533        0.020816               36  \n",
       "24           0.790960         0.774411        0.020340               39  \n",
       "32           0.790960         0.773288        0.022399               40  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_results = ModelGridSearch(GradientBoostingClassifier(), {'n_estimators': [100, 200 , 500, 1000],\n",
    "                                                             'loss': ['exponential', 'deviance'],\n",
    "                                                             'learning_rate': [1e-3, 1e-2, 1e-1, 0.5],\n",
    "                                                             'max_depth': [2, 3, 4, 5],\n",
    "                                                             'random_state': [1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.221489</td>\n",
       "      <td>0.121566</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.01</td>\n",
       "      <td>deviance</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'm...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.836158</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.882891</td>\n",
       "      <td>0.028961</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.01</td>\n",
       "      <td>exponential</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential',...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.837262</td>\n",
       "      <td>0.016731</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.224127</td>\n",
       "      <td>0.006808</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.836158</td>\n",
       "      <td>0.837262</td>\n",
       "      <td>0.023252</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.112534</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'ma...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.837262</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.147719</td>\n",
       "      <td>0.025975</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.01</td>\n",
       "      <td>exponential</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential',...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.836158</td>\n",
       "      <td>0.836139</td>\n",
       "      <td>0.014339</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.248201</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.001, 'loss': 'deviance', '...</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.304361</td>\n",
       "      <td>0.078661</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.001, 'loss': 'deviance', '...</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.380965</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001</td>\n",
       "      <td>deviance</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.001, 'loss': 'deviance', '...</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150475</td>\n",
       "      <td>0.012166</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.001</td>\n",
       "      <td>exponential</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.001, 'loss': 'exponential'...</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087765</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.001</td>\n",
       "      <td>exponential</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>{'learning_rate': 0.001, 'loss': 'exponential'...</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "59       1.221489      0.121566         0.006072        0.004238   \n",
       "46       0.882891      0.028961         0.003419        0.002671   \n",
       "89       0.224127      0.006808         0.002031        0.004062   \n",
       "88       0.112534      0.004177         0.001843        0.003167   \n",
       "43       1.147719      0.025975         0.005451        0.003508   \n",
       "..            ...           ...              ...             ...   \n",
       "25       0.248201      0.005628         0.001603        0.000801   \n",
       "28       0.304361      0.078661         0.002220        0.001320   \n",
       "29       0.380965      0.017061         0.001420        0.001347   \n",
       "1        0.150475      0.012166         0.001596        0.000489   \n",
       "0        0.087765      0.012345         0.002025        0.000061   \n",
       "\n",
       "   param_learning_rate   param_loss param_max_depth param_n_estimators  \\\n",
       "59                0.01     deviance               4               1000   \n",
       "46                0.01  exponential               5                500   \n",
       "89                 0.1     deviance               4                200   \n",
       "88                 0.1     deviance               4                100   \n",
       "43                0.01  exponential               4               1000   \n",
       "..                 ...          ...             ...                ...   \n",
       "25               0.001     deviance               4                200   \n",
       "28               0.001     deviance               5                100   \n",
       "29               0.001     deviance               5                200   \n",
       "1                0.001  exponential               2                200   \n",
       "0                0.001  exponential               2                100   \n",
       "\n",
       "   param_random_state                                             params  \\\n",
       "59                  1  {'learning_rate': 0.01, 'loss': 'deviance', 'm...   \n",
       "46                  1  {'learning_rate': 0.01, 'loss': 'exponential',...   \n",
       "89                  1  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...   \n",
       "88                  1  {'learning_rate': 0.1, 'loss': 'deviance', 'ma...   \n",
       "43                  1  {'learning_rate': 0.01, 'loss': 'exponential',...   \n",
       "..                ...                                                ...   \n",
       "25                  1  {'learning_rate': 0.001, 'loss': 'deviance', '...   \n",
       "28                  1  {'learning_rate': 0.001, 'loss': 'deviance', '...   \n",
       "29                  1  {'learning_rate': 0.001, 'loss': 'deviance', '...   \n",
       "1                   1  {'learning_rate': 0.001, 'loss': 'exponential'...   \n",
       "0                   1  {'learning_rate': 0.001, 'loss': 'exponential'...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "59           0.843575           0.821229           0.870787   \n",
       "46           0.843575           0.832402           0.865169   \n",
       "89           0.837989           0.832402           0.876404   \n",
       "88           0.837989           0.826816           0.876404   \n",
       "43           0.837989           0.832402           0.859551   \n",
       "..                ...                ...                ...   \n",
       "25           0.614525           0.614525           0.617978   \n",
       "28           0.614525           0.614525           0.617978   \n",
       "29           0.614525           0.614525           0.617978   \n",
       "1            0.614525           0.614525           0.617978   \n",
       "0            0.614525           0.614525           0.617978   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "59           0.820225           0.836158         0.838384        0.018470   \n",
       "46           0.814607           0.830508         0.837262        0.016731   \n",
       "89           0.803371           0.836158         0.837262        0.023252   \n",
       "88           0.803371           0.841808         0.837262        0.023700   \n",
       "43           0.814607           0.836158         0.836139        0.014339   \n",
       "..                ...                ...              ...             ...   \n",
       "25           0.617978           0.615819         0.616162        0.001555   \n",
       "28           0.617978           0.615819         0.616162        0.001555   \n",
       "29           0.617978           0.615819         0.616162        0.001555   \n",
       "1            0.617978           0.615819         0.616162        0.001555   \n",
       "0            0.617978           0.615819         0.616162        0.001555   \n",
       "\n",
       "    rank_test_score  \n",
       "59                1  \n",
       "46                2  \n",
       "89                2  \n",
       "88                2  \n",
       "43                5  \n",
       "..              ...  \n",
       "25              113  \n",
       "28              113  \n",
       "29              113  \n",
       "1               113  \n",
       "0               113  \n",
       "\n",
       "[128 rows x 18 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Users\\adam.jackson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lrm_results = ModelGridSearch(LogisticRegression(), {'C': [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2],\n",
    "                                                     'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                                                     'random_state': [1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.039280</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>7.463275e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10.0, 'random_state': 1, 'solver': 'newt...</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.029522</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>4.264961e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1, 'random_state': 1, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.023428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.007009</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>6.098768e-03</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 100.0, 'random_state': 1, 'solver': 'lib...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.020902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.043654</td>\n",
       "      <td>0.006772</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>4.888113e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 100.0, 'random_state': 1, 'solver': 'new...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.020902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10.0, 'random_state': 1, 'solver': 'libl...</td>\n",
       "      <td>0.832402</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.028444</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>2.602673e-03</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100.0, 'random_state': 1, 'solver': 'lbf...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.824916</td>\n",
       "      <td>0.021952</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.031664</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>8.919102e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10.0, 'random_state': 1, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.824916</td>\n",
       "      <td>0.021370</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.031942</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>1.183632e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 1, 'random_state': 1, 'solver': 'newton-...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.824916</td>\n",
       "      <td>0.021952</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.990174e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1, 'random_state': 1, 'solver': 'libline...</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.823793</td>\n",
       "      <td>0.022585</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.023153</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>6.249237e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'random_state': 1, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.821229</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.821549</td>\n",
       "      <td>0.012254</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.023586</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>6.308265e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'random_state': 1, 'solver': 'newto...</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.014656</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'random_state': 1, 'solver': 'libli...</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.801347</td>\n",
       "      <td>0.017886</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.033171</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>7.967953e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.01, 'random_state': 1, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.038964</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>7.976176e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.01, 'random_state': 1, 'solver': 'newt...</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.797980</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>6.303745e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.01, 'random_state': 1, 'solver': 'libl...</td>\n",
       "      <td>0.715084</td>\n",
       "      <td>0.793296</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.039289</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.048592</td>\n",
       "      <td>0.014613</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>4.997048e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 0.01, 'random_state': 1, 'solver': 'sag'}</td>\n",
       "      <td>0.653631</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.705948</td>\n",
       "      <td>0.035134</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.033061</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>9.770971e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 0.1, 'random_state': 1, 'solver': 'sag'}</td>\n",
       "      <td>0.653631</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.705948</td>\n",
       "      <td>0.035042</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.033935</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>4.883443e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 10.0, 'random_state': 1, 'solver': 'sag'}</td>\n",
       "      <td>0.653631</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.705948</td>\n",
       "      <td>0.035042</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.035396</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>6.306758e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 100.0, 'random_state': 1, 'solver': 'sag'}</td>\n",
       "      <td>0.653631</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.705948</td>\n",
       "      <td>0.035042</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.032168</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>6.307518e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 1, 'random_state': 1, 'solver': 'sag'}</td>\n",
       "      <td>0.653631</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.705948</td>\n",
       "      <td>0.035042</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004979</td>\n",
       "      <td>0.006478</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>2.050230e-03</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.001, 'random_state': 1, 'solver': 'lib...</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.699214</td>\n",
       "      <td>0.035925</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012022</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>3.972256e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.001, 'random_state': 1, 'solver': 'new...</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.691011</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.695847</td>\n",
       "      <td>0.037130</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.001, 'random_state': 1, 'solver': 'lbf...</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.674157</td>\n",
       "      <td>0.691011</td>\n",
       "      <td>0.723164</td>\n",
       "      <td>0.695847</td>\n",
       "      <td>0.037130</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058448</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>1.263500e-03</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 0.001, 'random_state': 1, 'solver': 'sag'}</td>\n",
       "      <td>0.636872</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.679775</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.694725</td>\n",
       "      <td>0.035909</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.033026</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>7.860620e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 1, 'random_state': 1, 'solver': 'saga'}</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.668539</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.693603</td>\n",
       "      <td>0.035453</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.030078</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>3.995895e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10.0, 'random_state': 1, 'solver': 'saga'}</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.668539</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.693603</td>\n",
       "      <td>0.035453</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.033351</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>7.839128e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 0.1, 'random_state': 1, 'solver': 'saga'}</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.668539</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.693603</td>\n",
       "      <td>0.035453</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.034381</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>4.877471e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 0.01, 'random_state': 1, 'solver': 'saga'}</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.668539</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.693603</td>\n",
       "      <td>0.035453</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.032515</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>7.971304e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 100.0, 'random_state': 1, 'solver': 'saga'}</td>\n",
       "      <td>0.642458</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.668539</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.717514</td>\n",
       "      <td>0.693603</td>\n",
       "      <td>0.035453</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059246</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>3.996141e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 0.001, 'random_state': 1, 'solver': 'saga'}</td>\n",
       "      <td>0.614525</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.679775</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.700565</td>\n",
       "      <td>0.687991</td>\n",
       "      <td>0.043384</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "20       0.039280      0.005251         0.000798    7.463275e-04      10   \n",
       "16       0.029522      0.002411         0.001995    4.264961e-07       1   \n",
       "27       0.007009      0.008668         0.003524    6.098768e-03     100   \n",
       "25       0.043654      0.006772         0.000399    4.888113e-04     100   \n",
       "22       0.008451      0.007103         0.000000    0.000000e+00      10   \n",
       "26       0.028444      0.005862         0.001301    2.602673e-03     100   \n",
       "21       0.031664      0.008462         0.000997    8.919102e-04      10   \n",
       "15       0.031942      0.013387         0.001047    1.183632e-03       1   \n",
       "17       0.004787      0.000746         0.001197    3.990174e-04       1   \n",
       "11       0.023153      0.006711         0.003125    6.249237e-03     0.1   \n",
       "10       0.023586      0.002694         0.000998    6.308265e-04     0.1   \n",
       "12       0.006249      0.007654         0.000000    0.000000e+00     0.1   \n",
       "6        0.033171      0.007555         0.001893    7.967953e-04    0.01   \n",
       "5        0.038964      0.008813         0.002593    7.976176e-04    0.01   \n",
       "7        0.007403      0.000787         0.001994    6.303745e-04    0.01   \n",
       "8        0.048592      0.014613         0.001610    4.997048e-04    0.01   \n",
       "13       0.033061      0.008737         0.000798    9.770971e-04     0.1   \n",
       "23       0.033935      0.004363         0.001596    4.883443e-04      10   \n",
       "28       0.035396      0.013035         0.000997    6.306758e-04     100   \n",
       "18       0.032168      0.004932         0.000997    6.307518e-04       1   \n",
       "2        0.004979      0.006478         0.001594    2.050230e-03   0.001   \n",
       "0        0.012022      0.002130         0.001199    3.972256e-04   0.001   \n",
       "1        0.012603      0.006305         0.000000    0.000000e+00   0.001   \n",
       "3        0.058448      0.006451         0.002994    1.263500e-03   0.001   \n",
       "19       0.033026      0.004856         0.000592    7.860620e-04       1   \n",
       "24       0.030078      0.001755         0.000200    3.995895e-04      10   \n",
       "14       0.033351      0.007296         0.000590    7.839128e-04     0.1   \n",
       "9        0.034381      0.002401         0.001594    4.877471e-04    0.01   \n",
       "29       0.032515      0.002571         0.001397    7.971304e-04     100   \n",
       "4        0.059246      0.009887         0.002195    3.996141e-04   0.001   \n",
       "\n",
       "   param_random_state param_solver  \\\n",
       "20                  1    newton-cg   \n",
       "16                  1        lbfgs   \n",
       "27                  1    liblinear   \n",
       "25                  1    newton-cg   \n",
       "22                  1    liblinear   \n",
       "26                  1        lbfgs   \n",
       "21                  1        lbfgs   \n",
       "15                  1    newton-cg   \n",
       "17                  1    liblinear   \n",
       "11                  1        lbfgs   \n",
       "10                  1    newton-cg   \n",
       "12                  1    liblinear   \n",
       "6                   1        lbfgs   \n",
       "5                   1    newton-cg   \n",
       "7                   1    liblinear   \n",
       "8                   1          sag   \n",
       "13                  1          sag   \n",
       "23                  1          sag   \n",
       "28                  1          sag   \n",
       "18                  1          sag   \n",
       "2                   1    liblinear   \n",
       "0                   1    newton-cg   \n",
       "1                   1        lbfgs   \n",
       "3                   1          sag   \n",
       "19                  1         saga   \n",
       "24                  1         saga   \n",
       "14                  1         saga   \n",
       "9                   1         saga   \n",
       "29                  1         saga   \n",
       "4                   1         saga   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "20  {'C': 10.0, 'random_state': 1, 'solver': 'newt...           0.832402   \n",
       "16     {'C': 1, 'random_state': 1, 'solver': 'lbfgs'}           0.826816   \n",
       "27  {'C': 100.0, 'random_state': 1, 'solver': 'lib...           0.837989   \n",
       "25  {'C': 100.0, 'random_state': 1, 'solver': 'new...           0.837989   \n",
       "22  {'C': 10.0, 'random_state': 1, 'solver': 'libl...           0.832402   \n",
       "26  {'C': 100.0, 'random_state': 1, 'solver': 'lbf...           0.826816   \n",
       "21  {'C': 10.0, 'random_state': 1, 'solver': 'lbfgs'}           0.826816   \n",
       "15  {'C': 1, 'random_state': 1, 'solver': 'newton-...           0.826816   \n",
       "17  {'C': 1, 'random_state': 1, 'solver': 'libline...           0.826816   \n",
       "11   {'C': 0.1, 'random_state': 1, 'solver': 'lbfgs'}           0.826816   \n",
       "10  {'C': 0.1, 'random_state': 1, 'solver': 'newto...           0.815642   \n",
       "12  {'C': 0.1, 'random_state': 1, 'solver': 'libli...           0.804469   \n",
       "6   {'C': 0.01, 'random_state': 1, 'solver': 'lbfgs'}           0.782123   \n",
       "5   {'C': 0.01, 'random_state': 1, 'solver': 'newt...           0.782123   \n",
       "7   {'C': 0.01, 'random_state': 1, 'solver': 'libl...           0.715084   \n",
       "8     {'C': 0.01, 'random_state': 1, 'solver': 'sag'}           0.653631   \n",
       "13     {'C': 0.1, 'random_state': 1, 'solver': 'sag'}           0.653631   \n",
       "23    {'C': 10.0, 'random_state': 1, 'solver': 'sag'}           0.653631   \n",
       "28   {'C': 100.0, 'random_state': 1, 'solver': 'sag'}           0.653631   \n",
       "18       {'C': 1, 'random_state': 1, 'solver': 'sag'}           0.653631   \n",
       "2   {'C': 0.001, 'random_state': 1, 'solver': 'lib...           0.642458   \n",
       "0   {'C': 0.001, 'random_state': 1, 'solver': 'new...           0.642458   \n",
       "1   {'C': 0.001, 'random_state': 1, 'solver': 'lbf...           0.642458   \n",
       "3    {'C': 0.001, 'random_state': 1, 'solver': 'sag'}           0.636872   \n",
       "19      {'C': 1, 'random_state': 1, 'solver': 'saga'}           0.642458   \n",
       "24   {'C': 10.0, 'random_state': 1, 'solver': 'saga'}           0.642458   \n",
       "14    {'C': 0.1, 'random_state': 1, 'solver': 'saga'}           0.642458   \n",
       "9    {'C': 0.01, 'random_state': 1, 'solver': 'saga'}           0.642458   \n",
       "29  {'C': 100.0, 'random_state': 1, 'solver': 'saga'}           0.642458   \n",
       "4   {'C': 0.001, 'random_state': 1, 'solver': 'saga'}           0.614525   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "20           0.826816           0.808989           0.808989   \n",
       "16           0.832402           0.803371           0.808989   \n",
       "27           0.821229           0.808989           0.808989   \n",
       "25           0.821229           0.808989           0.808989   \n",
       "22           0.821229           0.808989           0.808989   \n",
       "26           0.821229           0.797753           0.814607   \n",
       "21           0.821229           0.803371           0.808989   \n",
       "15           0.821229           0.797753           0.814607   \n",
       "17           0.821229           0.808989           0.797753   \n",
       "11           0.821229           0.808989           0.808989   \n",
       "10           0.826816           0.803371           0.803371   \n",
       "12           0.815642           0.780899           0.780899   \n",
       "6            0.804469           0.780899           0.792135   \n",
       "5            0.804469           0.780899           0.792135   \n",
       "7            0.793296           0.758427           0.797753   \n",
       "8            0.748603           0.685393           0.702247   \n",
       "13           0.743017           0.685393           0.702247   \n",
       "23           0.743017           0.685393           0.702247   \n",
       "28           0.743017           0.685393           0.702247   \n",
       "18           0.743017           0.685393           0.702247   \n",
       "2            0.748603           0.685393           0.696629   \n",
       "0            0.748603           0.674157           0.691011   \n",
       "1            0.748603           0.674157           0.691011   \n",
       "3            0.743017           0.679775           0.696629   \n",
       "19           0.743017           0.668539           0.696629   \n",
       "24           0.743017           0.668539           0.696629   \n",
       "14           0.743017           0.668539           0.696629   \n",
       "9            0.743017           0.668539           0.696629   \n",
       "29           0.743017           0.668539           0.696629   \n",
       "4            0.748603           0.679775           0.696629   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "20           0.864407         0.828283        0.020293                1  \n",
       "16           0.870056         0.828283        0.023428                1  \n",
       "27           0.864407         0.828283        0.020902                1  \n",
       "25           0.864407         0.828283        0.020902                1  \n",
       "22           0.864407         0.827160        0.020497                5  \n",
       "26           0.864407         0.824916        0.021952                6  \n",
       "21           0.864407         0.824916        0.021370                6  \n",
       "15           0.864407         0.824916        0.021952                6  \n",
       "17           0.864407         0.823793        0.022585                9  \n",
       "11           0.841808         0.821549        0.012254               10  \n",
       "10           0.841808         0.818182        0.014656               11  \n",
       "12           0.824859         0.801347        0.017886               12  \n",
       "6            0.830508         0.797980        0.018283               13  \n",
       "5            0.830508         0.797980        0.018283               13  \n",
       "7            0.830508         0.778900        0.039289               15  \n",
       "8            0.740113         0.705948        0.035134               16  \n",
       "13           0.745763         0.705948        0.035042               16  \n",
       "23           0.745763         0.705948        0.035042               16  \n",
       "28           0.745763         0.705948        0.035042               16  \n",
       "18           0.745763         0.705948        0.035042               16  \n",
       "2            0.723164         0.699214        0.035925               21  \n",
       "0            0.723164         0.695847        0.037130               22  \n",
       "1            0.723164         0.695847        0.037130               22  \n",
       "3            0.717514         0.694725        0.035909               24  \n",
       "19           0.717514         0.693603        0.035453               25  \n",
       "24           0.717514         0.693603        0.035453               25  \n",
       "14           0.717514         0.693603        0.035453               25  \n",
       "9            0.717514         0.693603        0.035453               25  \n",
       "29           0.717514         0.693603        0.035453               25  \n",
       "4            0.700565         0.687991        0.043384               30  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class that contains each of our scikit-learn models, and reduces required typing\n",
    "class SklearnClf():\n",
    "    def __init__(self, clf, **kwargs):\n",
    "        self.clf = clf(**kwargs)\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        return self.clf.fit(x_train, y_train)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        return self.clf.score(x,y)\n",
    "    \n",
    "    def print_score(self, x, y):\n",
    "        print(\"Score: \" + \"{:.2f}\".format(self.score(x,y)))\n",
    "    \n",
    "    def feature_importances(self):\n",
    "        return self.clf.feature_importances_\n",
    "    \n",
    "    def clone(self):\n",
    "        return clone(self.clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = SklearnClf(LogisticRegression, C=10, solver='newton-cg')\n",
    "knn = SklearnClf(KNeighborsClassifier, n_neighbors=4, p=1, weights='distance')\n",
    "rfc = SklearnClf(RandomForestClassifier, max_depth=5, min_samples_leaf=2, n_estimators=300, random_state=1)\n",
    "gbc = SklearnClf(GradientBoostingClassifier, n_estimators=1000, max_depth=4, loss='deviance', learning_rate=0.01, random_state=1)\n",
    "svc = SklearnClf(SVC, C=1e3, gamma='scale', random_state=1)\n",
    "mlpc = SklearnClf(MLPClassifier, max_iter=500, alpha=0.01, solver='adam', random_state=1)\n",
    "\n",
    "base_models = [lrm,\n",
    "               rfc,\n",
    "               gbc,\n",
    "               svc\n",
    "               #knn\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.84\n",
      "Score: 0.84\n",
      "Score: 0.93\n",
      "Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "for model in base_models:\n",
    "    model.fit(X_train, y_train)\n",
    "    model.print_score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a stacked model that takes as inputs, the predictions of a set of diverse base models. For each base model, there are k (5) sub-models that have the same hyperparameters, but are trained on subtly different training data (k folds approach). The mode prediction of those 5 sub-models is selected as the ultimate prediction for that base model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import clone\n",
    "from scipy.stats import mode\n",
    "\n",
    "class StackedEnsembleModel():\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for model in self.base_models]\n",
    "        self.meta_model_ = self.meta_model.clone()\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=1)\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_idx, holdout_idx in kfold.split(X, y):\n",
    "                instance = model.clone()\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X.iloc[train_idx,:], y.iloc[train_idx])\n",
    "                y_pred = instance.predict(X.iloc[holdout_idx,:])\n",
    "                out_of_fold_predictions[holdout_idx, i] = y_pred\n",
    "        \n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            mode(np.column_stack([sub_model.predict(X) for sub_model in base_model]),axis=1)[0]\\\n",
    "            for base_model in self.base_models_])\n",
    "        return self.meta_model_.predict(meta_features)\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        y_pred = self.predict(X_test)\n",
    "        count = 0\n",
    "        for prediction, actual in zip(y_pred, y_test):\n",
    "            if prediction == actual:\n",
    "                count += 1\n",
    "        self.score = count/len(y_test)\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model = StackedEnsembleModel(base_models, mlpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496071829405163"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_model.fit(X_train, y_train)\n",
    "stacked_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = test_df.drop(['PassengerId'], axis=1)\n",
    "test_ids = test_df['PassengerId']\n",
    "y_pred = stacked_model.predict(X_pred)\n",
    "\n",
    "submission_df = pd.DataFrame({'PassengerId': test_ids, 'Survived': y_pred})\n",
    "submission_df.to_csv(\"ajrj3_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
